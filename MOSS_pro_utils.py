"""MOSS Pro SDK - æ–‡ä»¶ä¸Šä¼ å·¥å…·

é€šè¿‡æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆmoss_pathï¼‰æŸ¥è¯¢è¯¥è·¯å¾„ä¸‹æ‰€æœ‰æ–‡ä»¶çš„åª’èµ„IDåˆ—è¡¨ï¼Œå¹¶æ”¯æŒæ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ã€‚

è®¤è¯æ–¹å¼ï¼šä½¿ç”¨æ˜æ–‡ AKSK (Access Key ID & Access Key Secret) è®¤è¯
- å‰ç«¯ç›´æ¥ä¼ è¾“æ˜æ–‡ AccessKeyId å’Œ AccessKeySecret
- åç«¯è‡ªåŠ¨å¤„ç†åŠ å¯†ã€éªŒè¯å’Œå®‰å…¨æ£€æŸ¥
- æ— éœ€å‰ç«¯è®¡ç®—å¤æ‚çš„ HMAC-SHA256 ç­¾å

æ–‡ä»¶ä¸Šä¼ ç‰¹æ€§ï¼š
- æ”¯æŒ OSS ç›´ä¼ ä¸Šä¼ 
- è¶…è¿‡ 100MB çš„æ–‡ä»¶è‡ªåŠ¨ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ 
- å°äº 100MB çš„æ–‡ä»¶ä½¿ç”¨å•åˆ†ç‰‡ä¸Šä¼ 
- æ”¯æŒä¸Šä¼ è¿›åº¦æ˜¾ç¤º
"""

import os
import asyncio
import hashlib
import mimetypes
from typing import Optional, Dict, Any, Callable
from pathlib import Path

import httpx

# ä½¿ç”¨æ ‡å‡† logging
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
log = logging.getLogger(__name__)

# åˆ†ç‰‡å¤§å°é˜ˆå€¼ï¼ˆ100MBï¼‰
CHUNK_SIZE_THRESHOLD = 100 * 1024 * 1024  # 100MB
# åˆ†ç‰‡å¤§å°ï¼ˆ10MBï¼Œé€‚åˆå¤§æ–‡ä»¶ï¼‰
PART_SIZE = 10 * 1024 * 1024  # 10MB


class MossConfig:
    """Moss API é…ç½® - ä½¿ç”¨æ˜æ–‡ AKSK è®¤è¯"""
    
    def __init__(
        self,
        base_url: Optional[str] = None,
        access_key_id: Optional[str] = None,
        access_key_secret: Optional[str] = None,
        bucket_name: Optional[str] = None,
        timeout: int = 300,
        max_retries: int = 3
    ):
        self.base_url = base_url or os.getenv("MOSS_BASE_URL", "http://localhost:8000")
        self.access_key_id = access_key_id or os.getenv("MOSS_ACCESS_KEY_ID")
        self.access_key_secret = access_key_secret or os.getenv("MOSS_ACCESS_KEY_SECRET")
        self.bucket_name = bucket_name or os.getenv("MOSS_BUCKET_NAME")
        self.timeout = timeout
        self.max_retries = max_retries
        
        if not self.access_key_id or not self.access_key_secret:
            raise ValueError("Moss Access Key ID and Access Key Secret must be provided via config or environment variables")
        
        if not self.bucket_name:
            raise ValueError("Moss Bucket Name must be provided via config or environment variables")


class MossAPIClient:
    """Moss API HTTP å®¢æˆ·ç«¯ - ä½¿ç”¨æ˜æ–‡ AKSK è®¤è¯
    
    é€šè¿‡ X-Access-Key-Id å’Œ X-Access-Key-Secret å¤´éƒ¨å‘é€æ˜æ–‡å‡­è¯ã€‚
    åç«¯ä¼šè‡ªåŠ¨éªŒè¯å‡­è¯å¹¶å¤„ç†æ‰€æœ‰å®‰å…¨æ£€æŸ¥ã€‚
    """
    
    def __init__(self, config: MossConfig):
        self.config = config
        self.client = httpx.AsyncClient(
            base_url=config.base_url,
            timeout=config.timeout,
            trust_env=False  # ç¦ç”¨ä»£ç†
        )
    
    async def __aenter__(self):
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.client.aclose()
    
    def _get_auth_headers(self) -> Dict[str, str]:
        """è·å–æ˜æ–‡AKSKè®¤è¯å¤´éƒ¨
        
        ä½¿ç”¨ X-Access-Key-Id å’Œ X-Access-Key-Secret å¤´éƒ¨è¿›è¡Œæ˜æ–‡è®¤è¯ã€‚
        åç«¯ä¼šè‡ªåŠ¨å¤„ç†åŠ å¯†å’ŒéªŒè¯ï¼Œå‰ç«¯æ— éœ€è®¡ç®—ç­¾åã€‚
        """
        # ç¡®ä¿ä¸ä¼šè¿”å›Noneå€¼
        access_key_id = self.config.access_key_id or ""
        access_key_secret = self.config.access_key_secret or ""
        
        return {
            "X-Access-Key-Id": access_key_id,
            "X-Access-Key-Secret": access_key_secret
        }
    
    async def request(
        self, 
        method: str, 
        url: str, 
        **kwargs
    ) -> httpx.Response:
        """å‘é€å¸¦æ˜æ–‡AKSKè®¤è¯çš„è¯·æ±‚
        
        ä½¿ç”¨ X-Access-Key-Id å’Œ X-Access-Key-Secret å¤´éƒ¨è¿›è¡Œè®¤è¯ã€‚
        åç«¯ä¼šè‡ªåŠ¨éªŒè¯æ˜æ–‡å‡­è¯ï¼Œæ— éœ€å‰ç«¯è®¡ç®—ç­¾åã€‚
        """
        full_url = f"{self.config.base_url}{url}"
        
        for attempt in range(self.config.max_retries):
            try:
                # å‡†å¤‡å¤´éƒ¨
                headers = kwargs.get("headers", {})
                
                # æ·»åŠ æ˜æ–‡AKSKè®¤è¯å¤´éƒ¨
                auth_headers = self._get_auth_headers()
                headers.update(auth_headers)
                
                # è®¾ç½®å†…å®¹ç±»å‹ï¼ˆå¦‚æœæœ‰JSONæ•°æ®ï¼‰
                if "json" in kwargs and "Content-Type" not in headers:
                    headers["Content-Type"] = "application/json"
                
                kwargs["headers"] = headers
                
                # å‘é€è¯·æ±‚
                response = await self.client.request(method, full_url, **kwargs)
                
                log.debug(f"{method} {url} -> {response.status_code}")
                # å¯¹äº404çŠ¶æ€ç ï¼Œé™é»˜å¤„ç†ä¸è®°å½•é”™è¯¯æ—¥å¿—ï¼Œé¿å…å¹²æ‰°æ­£å¸¸çš„æ–‡ä»¶å¤¹åˆ›å»ºæµç¨‹
                if response.status_code >= 400 and response.status_code != 404:
                    log.error(f"è¯·æ±‚å¤±è´¥: {response.text}")
                    try:
                        error_detail = response.json()
                        log.error(f"é”™è¯¯è¯¦æƒ…: {error_detail}")
                    except:
                        pass
                elif response.status_code == 404:
                    # 404çŠ¶æ€ç é™é»˜å¤„ç†ï¼Œç”¨äºæ–‡ä»¶å¤¹ä¸å­˜åœ¨çš„æ­£å¸¸æ£€æŸ¥æµç¨‹
                    log.debug(f"èµ„æºæœªæ‰¾åˆ° (404): {response.text}")
                
                response.raise_for_status()
                return response
                
            except httpx.RequestError as e:
                if attempt == self.config.max_retries - 1:
                    raise
                log.warning(f"Request failed (attempt {attempt + 1}): {e}")
                await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
        
        raise Exception("Max retries exceeded")


class MossProUtils:
    """Moss Pro å·¥å…· - æ”¯æŒæ–‡ä»¶ä¸Šä¼ å’Œåª’èµ„æŸ¥è¯¢
    
    é€šè¿‡æ–‡ä»¶å¤¹è·¯å¾„æŸ¥è¯¢è¯¥è·¯å¾„ä¸‹æ‰€æœ‰æ–‡ä»¶çš„åª’èµ„IDåˆ—è¡¨ã€‚
    æ”¯æŒé€’å½’/éé€’å½’æŸ¥è¯¢ã€çŠ¶æ€è¿‡æ»¤ã€åˆ†é¡µç­‰åŠŸèƒ½ã€‚
    åŒæ—¶æ”¯æŒè·å–æ–‡ä»¶å¤¹çš„å±‚çº§ç»“æ„ã€‚
    æ–°å¢ï¼šæ”¯æŒæ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ï¼Œä½¿ç”¨ OSS ç›´ä¼ ä¸Šä¼ ã€‚
    """
    
    def __init__(self, config: MossConfig):
        self.config = config
        self.api_client = MossAPIClient(config)
    
    async def __aenter__(self):
        await self.api_client.__aenter__()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.api_client.__aexit__(exc_type, exc_val, exc_tb)
    
    def _build_full_path(self, relative_path: str) -> str:
        """å°†ç”¨æˆ·æä¾›çš„ç›¸å¯¹è·¯å¾„ä¸ bucket_name æ‹¼æ¥æˆå®Œæ•´è·¯å¾„
        
        Args:
            relative_path: ç”¨æˆ·æä¾›çš„ç›¸å¯¹è·¯å¾„ï¼ˆä¸åŒ…å« bucket_nameï¼‰
                          ä¾‹å¦‚: "/" æˆ– "/videos/" æˆ– "/2025-10/image/"
        
        Returns:
            str: å®Œæ•´è·¯å¾„ï¼Œæ ¼å¼ä¸º /{bucket_name}{relative_path}
                ä¾‹å¦‚: "/é˜¿é‡Œ/" æˆ– "/é˜¿é‡Œ/videos/" æˆ– "/é˜¿é‡Œ/2025-10/image/"
        """
        bucket_name = self.config.bucket_name
        
        # ç¡®ä¿ relative_path ä»¥ / å¼€å¤´
        if not relative_path.startswith("/"):
            relative_path = "/" + relative_path
        
        # å¦‚æœç›¸å¯¹è·¯å¾„æ˜¯æ ¹ç›®å½• "/"ï¼Œè¿”å› /bucket_name/
        if relative_path == "/":
            return f"/{bucket_name}/"
        
        # å¦åˆ™æ‹¼æ¥: /bucket_name/relative_path
        # å»æ‰ relative_path å¼€å¤´çš„ /ï¼Œé¿å…åŒæ–œæ 
        relative_path_trimmed = relative_path.lstrip("/")
        full_path = f"/{bucket_name}/{relative_path_trimmed}"
        
        return full_path
    
    @staticmethod
    def _calculate_file_hash(file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶çš„ SHA256 å“ˆå¸Œå€¼
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            str: SHA256 å“ˆå¸Œå€¼ï¼ˆ64å­—ç¬¦ï¼‰
        """
        sha256_hash = hashlib.sha256()
        
        with open(file_path, 'rb') as f:
            while chunk := f.read(8192):  # 8KB å—
                sha256_hash.update(chunk)
        
        return sha256_hash.hexdigest()
    
    @staticmethod
    def _get_content_type(file_path: str) -> str:
        """è·å–æ–‡ä»¶çš„ MIME ç±»å‹
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            str: MIME ç±»å‹ï¼Œé»˜è®¤ä¸º application/octet-stream
        """
        content_type, _ = mimetypes.guess_type(file_path)
        return content_type or "application/octet-stream"
    
    async def _get_folder_id_by_path(self, folder_path: str) -> int:
        """é€šè¿‡æ–‡ä»¶å¤¹è·¯å¾„è·å– folder_idï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»º
        
        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆä¸å« bucket_nameï¼‰ï¼Œä¾‹å¦‚ "/" æˆ– "/videos/"
            
        Returns:
            int: folder_id
            
        Raises:
            Exception: å¦‚æœåˆ›å»ºå¤±è´¥
        """
        try:
            # å…¼å®¹ï¼šè‹¥è¾“å…¥ä¸ºå®Œæ•´è·¯å¾„ï¼ˆä»¥ /{bucket_name}/ å¼€å¤´ï¼‰ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™æŒ‰ç›¸å¯¹è·¯å¾„æ‹¼æ¥
            bucket_name = self.config.bucket_name
            if folder_path.startswith(f"/{bucket_name}/") or folder_path == f"/{bucket_name}/":
                full_path = folder_path
            else:
                full_path = self._build_full_path(folder_path)
            
            # è°ƒç”¨ç»“æ„æŸ¥è¯¢ APIï¼Œè·å– folder_id
            response = await self.api_client.request(
                "GET",
                "/api/v1/folders/structure/by-path",
                params={
                    "moss_path": full_path,
                    "include_bucket": False
                }
            )
            
            data = response.json()
            folder_id = data.get("base_folder_id")
            
            if not folder_id:
                raise Exception(f"æ— æ³•è·å–æ–‡ä»¶å¤¹ IDï¼Œè·¯å¾„: {folder_path}")
            
            log.info(f"é€šè¿‡è·¯å¾„è·å– folder_id æˆåŠŸ: {folder_path} -> {folder_id}")
            return folder_id
            
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 404:
                # æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨åˆ›å»ºï¼ˆé™é»˜å¤„ç†ï¼Œä¸è®°å½•é”™è¯¯æ—¥å¿—ï¼‰
                log.info(f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œå¼€å§‹è‡ªåŠ¨åˆ›å»º: {folder_path}")
                return await self._create_folder_path(folder_path)
            elif e.response.status_code == 401:
                # è®¤è¯å¤±è´¥
                error_msg = "è®¤è¯å¤±è´¥ï¼šAccess Key ID æˆ– Secret ä¸æ­£ç¡®ï¼Œè¯·æ£€æŸ¥æ‚¨çš„å‡­è¯ä¿¡æ¯"
                log.error(error_msg)
                raise Exception(error_msg)
            elif e.response.status_code == 403:
                # æƒé™ä¸è¶³ï¼Œè®°å½•æ¸…æ™°çš„ä¸­æ–‡æç¤º
                log.warning(f"æƒé™ä¸è¶³ï¼šæ— æ³•è®¿é—®è·¯å¾„ {folder_path}ï¼Œæ­£åœ¨å°è¯•ç›´æ¥åˆ›å»ºæ–‡ä»¶å¤¹")
                return await self._create_folder_path(folder_path)
            else:
                error_msg = f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç  {e.response.status_code}ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–è”ç³»ç®¡ç†å‘˜"
                log.error(error_msg)
                raise Exception(error_msg)
        except Exception as e:
            log.error(f"è·å–æ–‡ä»¶å¤¹ ID å¤±è´¥: folder_path={folder_path}, error={e}")
            raise
    
    async def _create_folder_path(self, folder_path: str) -> int:
        """é€’å½’åˆ›å»ºæ–‡ä»¶å¤¹è·¯å¾„ï¼ˆä¼˜åŒ–ç‰ˆï¼šåªåˆ›å»ºä¸å­˜åœ¨çš„æ–‡ä»¶å¤¹ï¼‰
        
        å°†å®Œæ•´è·¯å¾„æ‹†åˆ†ä¸ºå¤šå±‚ï¼Œä»æ ¹ç›®å½•å¼€å§‹é€å±‚æ£€æŸ¥ï¼Œåªåˆ›å»ºä¸å­˜åœ¨çš„æ–‡ä»¶å¤¹ã€‚
        
        **è·¯å¾„è½¬æ¢é€»è¾‘ï¼š**
        - ç”¨æˆ·è¾“å…¥: `/video/12/11/` (ç›¸å¯¹äºbucketçš„è·¯å¾„)
        - bucket_name: `dev`
        - å®é™…å®Œæ•´è·¯å¾„: `/dev/video/12/11/`
        - SDKä¼šè‡ªåŠ¨é€šè¿‡ `_build_full_path()` æ‹¼æ¥ bucket_name
        
        **åˆ›å»ºä¼˜åŒ–ï¼š**
        - å¦‚æœ `/video/` å’Œ `/video/12/` å·²å­˜åœ¨ï¼Œåªåˆ›å»º `/video/12/11/`
        - é¿å…é‡å¤æ£€æŸ¥å’Œåˆ›å»ºå·²å­˜åœ¨çš„æ–‡ä»¶å¤¹
        
        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆä¸å«bucket_nameï¼‰ï¼Œä¾‹å¦‚ "/video/12/11/"
                        SDKä¼šè‡ªåŠ¨æ‹¼æ¥ä¸º "/{bucket_name}/video/12/11/"
            
        Returns:
            int: æœ€ç»ˆåˆ›å»ºçš„æ–‡ä»¶å¤¹çš„ folder_id
            
        Raises:
            Exception: å¦‚æœåˆ›å»ºå¤±è´¥
        """
        try:
            # ç¡®ä¿è·¯å¾„æ ¼å¼æ­£ç¡®
            folder_path = folder_path.strip()
            if not folder_path.startswith("/"):
                folder_path = "/" + folder_path
            if not folder_path.endswith("/"):
                folder_path = folder_path + "/"
            
            # å¦‚æœæ˜¯æ ¹ç›®å½•ï¼Œç›´æ¥è·å–bucketçš„folder_id
            if folder_path == "/":
                full_path = self._build_full_path("/")
                response = await self.api_client.request(
                    "GET",
                    "/api/v1/folders/structure/by-path",
                    params={
                        "moss_path": full_path,
                        "include_bucket": False
                    }
                )
                data = response.json()
                return data.get("base_folder_id")
            
            # æ‹†åˆ†è·¯å¾„ä¸ºå„å±‚çº§
            # ä¾‹å¦‚: "/videos/2024/movie/" -> ["/videos/", "/videos/2024/", "/videos/2024/movie/"]
            parts = folder_path.strip("/").split("/")
            path_parts = []
            current_path = "/"
            for part in parts:
                current_path = current_path + part + "/"
                path_parts.append(current_path)
            
            log.info(f"è·¯å¾„å±‚çº§: {path_parts}")
            
            # ä»åå¾€å‰æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸å­˜åœ¨çš„å±‚çº§
            # ä¾‹å¦‚: å¦‚æœ /videos/ å’Œ /videos/2024/ å­˜åœ¨ï¼Œä½† /videos/2024/movie/ ä¸å­˜åœ¨
            # åˆ™ä» /videos/2024/movie/ å¼€å§‹åˆ›å»º
            first_missing_index = None
            parent_id = None
            
            # ä»å‰å¾€åæ£€æŸ¥æ¯ä¸€å±‚
            for i in range(len(path_parts)):
                try:
                    # ç›´æ¥è°ƒç”¨APIæ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨ï¼Œé¿å…é€’å½’è°ƒç”¨
                    full_path = self._build_full_path(path_parts[i])
                    response = await self.api_client.request(
                        "GET",
                        "/api/v1/folders/structure/by-path",
                        params={
                            "moss_path": full_path,
                            "include_bucket": False
                        }
                    )
                    data = response.json()
                    folder_id = data.get("base_folder_id")
                    
                    if not folder_id:
                        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸å­˜åœ¨çš„å±‚çº§
                        first_missing_index = i
                        log.info(f"âœ— æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {path_parts[i]}ï¼Œä»æ­¤å±‚å¼€å§‹åˆ›å»º")
                        break
                        
                    log.info(f"âœ“ æ–‡ä»¶å¤¹å·²å­˜åœ¨: {path_parts[i]} (ID: {folder_id})")
                    parent_id = folder_id  # è®°å½•æœ€åä¸€ä¸ªå­˜åœ¨çš„æ–‡ä»¶å¤¹IDä½œä¸ºçˆ¶ID
                except httpx.HTTPStatusError as e:
                    if e.response.status_code == 404:
                        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸å­˜åœ¨çš„å±‚çº§ï¼Œé™é»˜å¤„ç†
                        first_missing_index = i
                        log.info(f"âœ— æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {path_parts[i]}ï¼Œä»æ­¤å±‚å¼€å§‹åˆ›å»º")
                        break
                    else:
                        # å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡º
                        raise
                except Exception as e:
                    log.error(f"æ£€æŸ¥æ–‡ä»¶å¤¹å­˜åœ¨æ€§å¤±è´¥: path={path_parts[i]}, error={e}")
                    raise
            
            # å¦‚æœæ‰€æœ‰å±‚çº§éƒ½å­˜åœ¨ï¼Œç›´æ¥è¿”å›æœ€åä¸€å±‚çš„ID
            if first_missing_index is None:
                if parent_id is not None:
                    log.info(f"æ‰€æœ‰æ–‡ä»¶å¤¹éƒ½å·²å­˜åœ¨ï¼Œè¿”å›æœ€ç»ˆID: {parent_id}")
                    return parent_id
                else:
                    # è¿™ç§æƒ…å†µç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼Œä½†ä¸ºäº†ç±»å‹å®‰å…¨æ·»åŠ å¤„ç†
                    raise Exception("æ— æ³•ç¡®å®šæ–‡ä»¶å¤¹ID")
            
            # å¦‚æœç¬¬ä¸€å±‚å°±ä¸å­˜åœ¨ï¼Œparent_id åº”è¯¥æ˜¯ bucket çš„ folder_id
            if parent_id is None:
                root_path = self._build_full_path("/")
                root_response = await self.api_client.request(
                    "GET",
                    "/api/v1/folders/structure/by-path",
                    params={
                        "moss_path": root_path,
                        "include_bucket": False
                    }
                )
                root_data = root_response.json()
                parent_id = root_data.get("base_folder_id")
                log.info(f"è·å–bucketæ ¹ç›®å½•ID: {parent_id}")
            
            # ä»ç¬¬ä¸€ä¸ªä¸å­˜åœ¨çš„å±‚çº§å¼€å§‹ï¼Œé€å±‚åˆ›å»ºæ–‡ä»¶å¤¹
            current_folder_id = parent_id
            for i in range(first_missing_index, len(path_parts)):
                folder_name = parts[i]
                
                log.info(f"åˆ›å»ºæ–‡ä»¶å¤¹: {folder_name} (çˆ¶ID: {parent_id}, è·¯å¾„: {path_parts[i]})")
                
                # è°ƒç”¨åˆ›å»ºæ–‡ä»¶å¤¹ APIï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
                max_retries = 3
                create_response = None
                for attempt in range(max_retries):
                    try:
                        create_response = await self.api_client.request(
                            "POST",
                            "/api/v1/folders/",
                            json={
                                "name": folder_name,
                                "parent_id": parent_id
                            }
                        )
                        break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
                    except httpx.HTTPStatusError as e:
                        if e.response.status_code == 403:
                            # æƒé™ä¸è¶³ï¼Œè®°å½•æ¸…æ™°çš„ä¸­æ–‡æç¤ºä½†ç»§ç»­å°è¯•
                            log.warning(f"åˆ›å»ºæ–‡ä»¶å¤¹æƒé™ä¸è¶³: {folder_name} (å°è¯• {attempt + 1}/{max_retries})ï¼Œè¯·æ£€æŸ¥è´¦å·æƒé™")
                            if attempt == max_retries - 1:  # æœ€åä¸€æ¬¡å°è¯•ä»ç„¶å¤±è´¥
                                raise Exception(f"åˆ›å»ºæ–‡ä»¶å¤¹æƒé™ä¸è¶³: {folder_name}ï¼Œè¯·æ£€æŸ¥è´¦å·æƒé™æˆ–è”ç³»ç®¡ç†å‘˜")
                            await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                        else:
                            raise
                    except Exception as e:
                        if attempt == max_retries - 1:  # æœ€åä¸€æ¬¡å°è¯•ä»ç„¶å¤±è´¥
                            raise Exception(f"åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥: {folder_name}ï¼Œé”™è¯¯ä¿¡æ¯: {str(e)}")
                        log.warning(f"åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥: {folder_name} (å°è¯• {attempt + 1}/{max_retries}): {e}ï¼Œ1ç§’åé‡è¯•")
                        await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                
                if create_response is None:
                    raise Exception(f"åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥: {folder_name}")
                
                create_data = create_response.json()
                current_folder_id = create_data.get("id")
                parent_id = current_folder_id  # ä¸‹ä¸€å±‚çš„çˆ¶IDå°±æ˜¯å½“å‰åˆ›å»ºçš„ID
                
                log.info(f"âœ… æ–‡ä»¶å¤¹åˆ›å»ºæˆåŠŸ: {path_parts[i]} (ID: {current_folder_id})")
            
            log.info(f"âœ… è·¯å¾„åˆ›å»ºå®Œæˆ: {folder_path} (æœ€ç»ˆID: {current_folder_id})")
            return current_folder_id
            
        except Exception as e:
            log.error(f"åˆ›å»ºæ–‡ä»¶å¤¹è·¯å¾„å¤±è´¥: folder_path={folder_path}, error={e}")
            raise
    
    async def upload_file(
        self,
        file_path: str,
        folder_path: str = "/",
        tags: Optional[list] = None,
        progress_callback: Optional[Callable[[int, int], None]] = None,
        enable_content_analysis: bool = False,
        frame_level: str = "medium"
    ) -> Dict[str, Any]:
        """ä¸Šä¼ æ–‡ä»¶åˆ° MOSSï¼ˆä½¿ç”¨ OSS ç›´ä¼ ï¼‰
        
        æ”¯æŒå¤§æ–‡ä»¶åˆ†ç‰‡ä¸Šä¼ ï¼ˆè¶…è¿‡ 100MB è‡ªåŠ¨åˆ†ç‰‡ï¼‰ã€‚
        å¦‚æœç›®æ ‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºã€‚
        
        Args:
            file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            folder_path: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ï¼Œä¾‹å¦‚ "/" æˆ– "/videos/"ï¼Œé»˜è®¤ä¸ºæ ¹ç›®å½•
                        å¦‚æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»º
            tags: æ–‡ä»¶æ ‡ç­¾åˆ—è¡¨ï¼Œå¯é€‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (uploaded_bytes, total_bytes)
            enable_content_analysis: æ˜¯å¦å¯ç”¨AIå†…å®¹åˆ†æï¼ˆä»…æ”¯æŒè§†é¢‘æ–‡ä»¶ï¼‰
            frame_level: æŠ½å¸§ç­‰çº§: low/medium/high
            
        Returns:
            Dict: åŒ…å«ä¸Šä¼ ç»“æœï¼ŒåŒ…æ‹¬ï¼š
                - success: æ˜¯å¦æˆåŠŸ
                - moss_id: MOSS ID
                - oss_path: OSS è·¯å¾„
                - file_size: æ–‡ä»¶å¤§å°
                - message: æç¤ºä¿¡æ¯
                
        Examples:
            ä¸Šä¼ åˆ°æ ¹ç›®å½•ï¼š
            ```python
            result = await moss.upload_file(
                file_path="/path/to/video.mp4"
            )
            print(f"ä¸Šä¼ æˆåŠŸ: {result['moss_id']}")
            ```
            
            ä¸Šä¼ åˆ°æŒ‡å®šæ–‡ä»¶å¤¹ï¼š
            ```python
            result = await moss.upload_file(
                file_path="/path/to/video.mp4",
                folder_path="/videos/"
            )
            print(f"ä¸Šä¼ æˆåŠŸ: {result['moss_id']}")
            ```
            
            å¸¦è¿›åº¦æ˜¾ç¤ºï¼š
            ```python
            def on_progress(uploaded, total):
                percent = (uploaded / total) * 100
                print(f"è¿›åº¦: {percent:.1f}%")
            
            result = await moss.upload_file(
                file_path="/path/to/large_video.mp4",
                folder_path="/videos/",
                progress_callback=on_progress
            )
            ```
        """
        # é€šè¿‡è·¯å¾„è·å– folder_idï¼ˆè‡ªåŠ¨åˆ›å»ºä¸å­˜åœ¨çš„æ–‡ä»¶å¤¹ï¼‰
        folder_id = await self._get_folder_id_by_path(folder_path)
        
        file_path_obj = Path(file_path)
        
        if not file_path_obj.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        file_name = file_path_obj.name
        file_size = file_path_obj.stat().st_size
        
        log.info(f"ğŸš€ å¼€å§‹ä¸Šä¼ æ–‡ä»¶: {file_name}, å¤§å°: {file_size} å­—èŠ‚ ({file_size / 1024 / 1024:.2f} MB)")
        
        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        log.info("ğŸ” è®¡ç®—æ–‡ä»¶ SHA256 å“ˆå¸Œ...")
        file_hash = self._calculate_file_hash(file_path)
        log.info(f"âœ… æ–‡ä»¶å“ˆå¸Œ: {file_hash[:16]}...")
        
        # è·å– MIME ç±»å‹
        content_type = self._get_content_type(file_path)
        log.info(f"ğŸ“„ æ–‡ä»¶ç±»å‹: {content_type}")
        
        # 1. åˆå§‹åŒ–åˆ†ç‰‡ä¸Šä¼ 
        log.info("ğŸ“¤ åˆå§‹åŒ–åˆ†ç‰‡ä¸Šä¼ ...")
        init_request = {
            "file_name": file_name,
            "file_size": file_size,
            "file_hash": file_hash,
            "folder_id": folder_id,
            "content_type": content_type,
            "tags": tags or [],
            "enable_content_analysis": enable_content_analysis,
            "frame_level": frame_level
        }
        
        init_response = await self.api_client.request(
            "POST",
            "/api/v1/oss-direct-upload/init-multipart",
            json=init_request
        )
        
        init_data = init_response.json()
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆMOSS äº‘ç«¯å·²æœ‰ç›¸åŒæ–‡ä»¶ï¼‰
        if init_data.get("file_exists"):
            if init_data.get("is_active"):
                existing_moss_id = init_data.get("existing_moss_id")
                log.debug(f"ğŸ“¦ MOSS äº‘ç«¯å·²å­˜åœ¨ç›¸åŒæ–‡ä»¶ï¼Œå¤ç”¨ MOSS ID: {existing_moss_id}")
                return {
                    "success": False,
                    "file_exists": True,
                    "existing_moss_id": existing_moss_id,
                    "message": init_data.get("message", "æ–‡ä»¶å·²å­˜åœ¨")
                }
            else:
                log.debug("ğŸ“¦ MOSS äº‘ç«¯æ–‡ä»¶å·²é‡æ–°æ¿€æ´»")
                return {
                    "success": True,
                    "file_exists": True,
                    "existing_moss_id": init_data.get("existing_moss_id"),
                    "message": init_data.get("message", "æ–‡ä»¶å·²é‡æ–°æ¿€æ´»")
                }
        
        upload_token = init_data["upload_token"]
        upload_id = init_data["upload_id"]
        oss_key = init_data["oss_key"]
        
        log.info(f"âœ… åˆå§‹åŒ–æˆåŠŸ - upload_id: {upload_id[:16]}...")
        
        # 2. ä¸Šä¼ åˆ†ç‰‡
        # åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ†ç‰‡ä¸Šä¼ 
        use_multipart = file_size > CHUNK_SIZE_THRESHOLD
        
        if use_multipart:
            log.info(f"ğŸ“¦ ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ ï¼ˆæ–‡ä»¶å¤§å°è¶…è¿‡ 100MBï¼‰")
            # è®¡ç®—åˆ†ç‰‡æ•°é‡
            total_parts = (file_size + PART_SIZE - 1) // PART_SIZE
            log.info(f"åˆ†ç‰‡æ•°é‡: {total_parts}, æ¯ç‰‡å¤§å°: {PART_SIZE / 1024 / 1024:.2f} MB")
            actual_part_size = PART_SIZE
        else:
            log.info(f"ğŸ“¤ ä½¿ç”¨å•åˆ†ç‰‡ä¸Šä¼ ï¼ˆæ–‡ä»¶å¤§å°å°äº 100MBï¼‰")
            total_parts = 1
            actual_part_size = file_size  # å•åˆ†ç‰‡æ—¶ï¼Œåˆ†ç‰‡å¤§å°å°±æ˜¯æ•´ä¸ªæ–‡ä»¶å¤§å°
        
        uploaded_bytes = 0
        parts = []
        
        with open(file_path, 'rb') as f:
            for part_number in range(1, total_parts + 1):
                # è®¡ç®—å½“å‰åˆ†ç‰‡çš„èµ·å§‹å’Œç»“æŸä½ç½®
                if use_multipart:
                    start_pos = (part_number - 1) * PART_SIZE
                    end_pos = min(start_pos + PART_SIZE, file_size)
                else:
                    # å•åˆ†ç‰‡ä¸Šä¼ ï¼Œè¯»å–æ•´ä¸ªæ–‡ä»¶
                    start_pos = 0
                    end_pos = file_size
                part_size = end_pos - start_pos
                
                log.info(f"ğŸ“¤ ä¸Šä¼ åˆ†ç‰‡ {part_number}/{total_parts} ({part_size / 1024 / 1024:.2f} MB)...")
                
                # è¯»å–åˆ†ç‰‡æ•°æ®
                f.seek(start_pos)
                part_data = f.read(part_size)
                
                # è·å–é¢„ç­¾å URL
                url_response = await self.api_client.request(
                    "POST",
                    "/api/v1/oss-direct-upload/get-upload-url",
                    json={
                        "upload_token": upload_token,
                        "part_number": part_number
                    }
                )
                
                url_data = url_response.json()
                upload_url = url_data["upload_url"]
                
                # ä¸Šä¼ åˆ†ç‰‡åˆ° OSSï¼ˆå¢åŠ è¶…æ—¶æ—¶é—´å’Œé‡è¯•æœºåˆ¶ï¼‰
                max_upload_retries = 3
                upload_success = False
                last_error = None
                
                for upload_attempt in range(max_upload_retries):
                    try:
                        # æ ¹æ®åˆ†ç‰‡å¤§å°åŠ¨æ€è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆæ¯MB 30ç§’ï¼Œæœ€å°‘120ç§’ï¼Œæœ€å¤š600ç§’ï¼‰
                        timeout_per_mb = 30
                        min_timeout = 120
                        max_timeout = 600
                        calculated_timeout = (part_size / 1024 / 1024) * timeout_per_mb
                        timeout_seconds = max(min_timeout, min(calculated_timeout, max_timeout))
                        
                        log.debug(f"åˆ†ç‰‡ {part_number} ä¸Šä¼ è¶…æ—¶è®¾ç½®: {timeout_seconds}ç§’ (åˆ†ç‰‡å¤§å°: {part_size / 1024 / 1024:.2f} MB)")
                        
                        # åˆ›å»ºHTTPå®¢æˆ·ç«¯ï¼Œç¦ç”¨ä»£ç†ï¼Œä½¿ç”¨æ›´å®½æ¾çš„è¶…æ—¶é…ç½®
                        timeout_config = httpx.Timeout(
                            connect=30.0,  # è¿æ¥è¶…æ—¶30ç§’
                            read=timeout_seconds,  # è¯»å–è¶…æ—¶æ ¹æ®æ–‡ä»¶å¤§å°åŠ¨æ€è®¾ç½®
                            write=timeout_seconds,  # å†™å…¥è¶…æ—¶
                            pool=30.0  # è¿æ¥æ± è¶…æ—¶
                        )
                        
                        async with httpx.AsyncClient(
                            timeout=timeout_config,
                            trust_env=False,  # ç¦ç”¨ä»£ç†
                            follow_redirects=True,
                            limits=httpx.Limits(max_keepalive_connections=5, max_connections=10)
                        ) as upload_client:
                            # OSSåˆ†ç‰‡ä¸Šä¼ ä¸éœ€è¦Content-Typeå¤´éƒ¨ï¼Œè®©OSSè‡ªåŠ¨æ£€æµ‹
                            upload_response = await upload_client.put(
                                upload_url,
                                content=part_data
                            )
                            upload_response.raise_for_status()
                            
                            # è·å– ETagï¼ˆOSSè¿”å›çš„ETagå¯èƒ½å¸¦å¼•å·ï¼Œéœ€è¦å»é™¤ï¼‰
                            etag = upload_response.headers.get("ETag", "").strip('"').strip("'")
                            if not etag:
                                # å¦‚æœå“åº”å¤´æ²¡æœ‰ETagï¼Œå°è¯•ä»å“åº”ä½“è·å–
                                log.warning(f"åˆ†ç‰‡ {part_number} å“åº”å¤´ä¸­æ²¡æœ‰ETagï¼Œå°è¯•å…¶ä»–æ–¹å¼è·å–")
                                # OSSåˆ†ç‰‡ä¸Šä¼ PUTè¯·æ±‚é€šå¸¸ä¼šåœ¨å“åº”å¤´ä¸­è¿”å›ETag
                                raise Exception("æ— æ³•è·å–ETagï¼Œä¸Šä¼ å¯èƒ½å¤±è´¥")
                            
                            parts.append({
                                "part_number": part_number,
                                "etag": etag
                            })
                            
                            upload_success = True
                            log.info(f"âœ… åˆ†ç‰‡ {part_number} ä¸Šä¼ æˆåŠŸï¼ŒETag: {etag[:16]}...")
                            break
                            
                    except (httpx.ReadError, httpx.TimeoutException, httpx.NetworkError, httpx.HTTPStatusError) as e:
                        last_error = e
                        error_msg = str(e)
                        if isinstance(e, httpx.HTTPStatusError):
                            error_msg = f"HTTP {e.response.status_code}: {e.response.text[:200]}"
                        
                        if upload_attempt < max_upload_retries - 1:
                            wait_time = 2 ** upload_attempt  # æŒ‡æ•°é€€é¿ï¼š1ç§’ã€2ç§’ã€4ç§’
                            log.warning(f"åˆ†ç‰‡ {part_number} ä¸Šä¼ å¤±è´¥ï¼ˆå°è¯• {upload_attempt + 1}/{max_upload_retries}ï¼‰: {error_msg}ï¼Œ{wait_time}ç§’åé‡è¯•...")
                            await asyncio.sleep(wait_time)
                        else:
                            log.error(f"åˆ†ç‰‡ {part_number} ä¸Šä¼ å¤±è´¥ï¼Œå·²é‡è¯• {max_upload_retries} æ¬¡")
                            raise Exception(f"åˆ†ç‰‡ {part_number} ä¸Šä¼ å¤±è´¥ï¼Œå·²é‡è¯• {max_upload_retries} æ¬¡: {error_msg}")
                    except Exception as e:
                        last_error = e
                        error_msg = str(e)
                        if upload_attempt < max_upload_retries - 1:
                            wait_time = 2 ** upload_attempt
                            log.warning(f"åˆ†ç‰‡ {part_number} ä¸Šä¼ å¤±è´¥ï¼ˆå°è¯• {upload_attempt + 1}/{max_upload_retries}ï¼‰: {error_msg}ï¼Œ{wait_time}ç§’åé‡è¯•...")
                            await asyncio.sleep(wait_time)
                        else:
                            raise Exception(f"åˆ†ç‰‡ {part_number} ä¸Šä¼ å¤±è´¥ï¼Œå·²é‡è¯• {max_upload_retries} æ¬¡: {error_msg}")
                
                if not upload_success:
                    error_msg = str(last_error) if last_error else "æœªçŸ¥é”™è¯¯"
                    raise Exception(f"åˆ†ç‰‡ {part_number} ä¸Šä¼ å¤±è´¥: {error_msg}")
                
                uploaded_bytes += part_size
                
                # è°ƒç”¨è¿›åº¦å›è°ƒ
                if progress_callback:
                    progress_callback(uploaded_bytes, file_size)
                
                log.info(f"âœ… åˆ†ç‰‡ {part_number}/{total_parts} ä¸Šä¼ å®Œæˆ")
        
        log.info(f"âœ… æ‰€æœ‰åˆ†ç‰‡ä¸Šä¼ å®Œæˆ ({uploaded_bytes / 1024 / 1024:.2f} MB)")
        
        # 3. å®Œæˆä¸Šä¼ 
        log.info("ğŸ”— å®Œæˆåˆ†ç‰‡ä¸Šä¼ ...")
        complete_response = await self.api_client.request(
            "POST",
            "/api/v1/oss-direct-upload/complete-multipart",
            json={
                "upload_token": upload_token,
                "parts": parts
            }
        )
        
        complete_data = complete_response.json()
        
        log.info(f"ğŸ‰ æ–‡ä»¶ä¸Šä¼ æˆåŠŸ!")
        log.info(f"  â€¢ MOSS ID: {complete_data['moss_id']}")
        log.info(f"  â€¢ OSS è·¯å¾„: {complete_data['oss_path']}")
        log.info(f"  â€¢ æ–‡ä»¶å¤§å°: {complete_data['file_size'] / 1024 / 1024:.2f} MB")
        
        return {
            "success": True,
            "moss_id": complete_data["moss_id"],
            "oss_path": complete_data["oss_path"],
            "file_size": complete_data["file_size"],
            "message": complete_data.get("message", "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ")
        }
    
    async def get_file_metadata(self, moss_id: str) -> Dict[str, Any]:
        """é€šè¿‡ MOSS ID è·å–æ–‡ä»¶å…ƒæ•°æ®
        
        Args:
            moss_id: MOSS æ–‡ä»¶ ID
            
        Returns:
            Dict: æ–‡ä»¶å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
                - moss_id: MOSS ID
                - oss_path: OSS è·¯å¾„
                - moss_path: MOSS è·¯å¾„
                - file_name: æ–‡ä»¶å
                - file_size: æ–‡ä»¶å¤§å°
                - file_format: æ–‡ä»¶æ ¼å¼
                - video_metadata: è§†é¢‘å…ƒæ•°æ®ï¼ˆå¦‚æœæ˜¯è§†é¢‘ï¼‰
                  - width: å®½åº¦
                  - height: é«˜åº¦
                  - duration: æ—¶é•¿ï¼ˆç§’ï¼‰
                  - frame_rate: å¸§ç‡
                  - bitrate: ç ç‡
                  - video_codec: è§†é¢‘ç¼–ç 
        """
        try:
            response = await self.api_client.request(
                "GET",
                f"/api/v1/files/{moss_id}"
            )
            return response.json()
        except Exception as e:
            log.error(f"è·å–æ–‡ä»¶å…ƒæ•°æ®å¤±è´¥: moss_id={moss_id}, error={e}")
            raise
    
    async def wait_for_video_metadata(
        self,
        moss_id: str,
        max_wait_seconds: int = 120,
        poll_interval: int = 5
    ) -> Dict[str, Any]:
        """ç­‰å¾…è§†é¢‘å…ƒæ•°æ®å°±ç»ªï¼ˆICE åª’èµ„æ³¨å†Œå®Œæˆï¼‰
        
        ä¸Šä¼ è§†é¢‘åï¼ŒICE åª’èµ„æ³¨å†Œæ˜¯å¼‚æ­¥çš„ï¼Œéœ€è¦ç­‰å¾…ä¸€æ®µæ—¶é—´æ‰èƒ½è·å–åˆ°æ—¶é•¿ç­‰å…ƒæ•°æ®ã€‚
        æ­¤æ–¹æ³•ä¼šè½®è¯¢æŸ¥è¯¢ï¼Œç›´åˆ°è·å–åˆ°è§†é¢‘æ—¶é•¿æˆ–è¶…æ—¶ã€‚
        
        Args:
            moss_id: MOSS æ–‡ä»¶ ID
            max_wait_seconds: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 120 ç§’
            poll_interval: è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 5 ç§’
            
        Returns:
            Dict: æ–‡ä»¶å…ƒæ•°æ®ï¼ˆåŒ…å« video_metadataï¼‰
            
        Raises:
            TimeoutError: ç­‰å¾…è¶…æ—¶
            Exception: è·å–å…ƒæ•°æ®å¤±è´¥
        """
        elapsed = 0
        
        while elapsed < max_wait_seconds:
            try:
                metadata = await self.get_file_metadata(moss_id)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰è§†é¢‘å…ƒæ•°æ®å’Œæ—¶é•¿
                video_metadata = metadata.get("video_metadata")
                if video_metadata and video_metadata.get("duration"):
                    log.info(f"è§†é¢‘å…ƒæ•°æ®å°±ç»ª: duration={video_metadata['duration']}s")
                    return metadata
                
                log.info(f"ç­‰å¾…è§†é¢‘å…ƒæ•°æ®å°±ç»ª... ({elapsed}/{max_wait_seconds}s)")
                
            except Exception as e:
                log.warning(f"æŸ¥è¯¢å…ƒæ•°æ®å¤±è´¥ï¼Œç»§ç»­ç­‰å¾…: {e}")
            
            await asyncio.sleep(poll_interval)
            elapsed += poll_interval
        
        raise TimeoutError(f"ç­‰å¾…è§†é¢‘å…ƒæ•°æ®è¶…æ—¶ï¼ˆ{max_wait_seconds}ç§’ï¼‰")
    
    async def get_video_snapshot_urls(
        self,
        oss_path: str,
        timestamps_ms: list[int],
        width: int = 720,
        expire_seconds: int = 3600
    ) -> Dict[str, Any]:
        """æ‰¹é‡è·å–è§†é¢‘æˆªå¸§ç­¾å URL
        
        é€šè¿‡ OSS è§†é¢‘æˆªå¸§åŠŸèƒ½ç”Ÿæˆå¸¦ç­¾åçš„ç¼©ç•¥å›¾ URL åˆ—è¡¨ã€‚
        å¦‚æœæ—¶é—´æˆ³è¶…è¿‡ 100 ä¸ªï¼Œä¼šè‡ªåŠ¨åˆ†æ‰¹è¯·æ±‚ã€‚
        
        Args:
            oss_path: OSS ä¸Šçš„è§†é¢‘è·¯å¾„ï¼ˆå¦‚ Dev/2025-12/video/xxx.mp4ï¼‰
            timestamps_ms: éœ€è¦æˆªå¸§çš„æ—¶é—´ç‚¹åˆ—è¡¨ï¼ˆæ¯«ç§’ï¼‰
            width: ç¼©ç•¥å›¾å®½åº¦ï¼Œé»˜è®¤ 720
            expire_seconds: ç­¾å URL æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 3600
            
        Returns:
            Dict: åŒ…å«ç­¾å URL åˆ—è¡¨
                - success: æ˜¯å¦æˆåŠŸ
                - urls: URL åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« timestamp_ms å’Œ url
                
        Examples:
            ```python
            result = await moss.get_video_snapshot_urls(
                oss_path="Dev/2025-12/video/xxx.mp4",
                timestamps_ms=[0, 500, 1000, 1500, 2000],
                width=720,
                expire_seconds=3600
            )
            for item in result["urls"]:
                print(f"{item['timestamp_ms']}ms: {item['url']}")
            ```
        """
        try:
            BATCH_SIZE = 100
            all_urls = []
            total_timestamps = len(timestamps_ms)
            
            log.info(f"è·å–è§†é¢‘æˆªå¸§ç­¾å URL: {oss_path}, å…± {total_timestamps} å¸§")
            
            # åˆ†æ‰¹è¯·æ±‚
            for i in range(0, total_timestamps, BATCH_SIZE):
                batch_timestamps = timestamps_ms[i:i + BATCH_SIZE]
                batch_num = i // BATCH_SIZE + 1
                total_batches = (total_timestamps + BATCH_SIZE - 1) // BATCH_SIZE
                
                log.info(f"è·å–æˆªå¸§ URL æ‰¹æ¬¡ {batch_num}/{total_batches}ï¼Œå…± {len(batch_timestamps)} å¸§")
                
                response = await self.api_client.request(
                    "POST",
                    "/api/v1/oss/video-snapshot-urls",
                    json={
                        "oss_path": oss_path,
                        "timestamps_ms": batch_timestamps,
                        "width": width,
                        "expire_seconds": expire_seconds
                    }
                )
                
                data = response.json()
                batch_urls = data.get("urls", [])
                all_urls.extend(batch_urls)
            
            log.info(f"è·å–æˆªå¸§ URL æˆåŠŸï¼Œå…± {len(all_urls)} ä¸ª")
            
            return {
                "success": True,
                "urls": all_urls
            }
            
        except Exception as e:
            log.error(f"è·å–è§†é¢‘æˆªå¸§ URL å¤±è´¥: {e}")
            return {
                "success": False,
                "urls": [],
                "error": str(e)
            }
    
    async def get_folder_media_ids(
        self,
        folder_path: str,
        recursive: bool = False,
        include_pending: bool = False,
        include_raw: bool = True,
        media_status: Optional[str] = None,
        page: Optional[int] = None,
        page_size: Optional[int] = None
    ) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰æ–‡ä»¶çš„åª’èµ„IDåˆ—è¡¨ - åŸºäºè·¯å¾„æŸ¥è¯¢
        
        é€šè¿‡æ–‡ä»¶å¤¹çš„é€»è¾‘è·¯å¾„è·å–è¯¥è·¯å¾„ä¸‹æ‰€æœ‰æ–‡ä»¶çš„åª’èµ„ä¿¡æ¯ã€‚
        è·¯å¾„ä¸éœ€è¦åŒ…å« bucket_nameï¼ŒSDK ä¼šè‡ªåŠ¨æ·»åŠ ã€‚
        
        Args:
            folder_path: æ–‡ä»¶å¤¹çš„é€»è¾‘è·¯å¾„ï¼ˆä¸å« bucket_nameï¼‰
            recursive: æ˜¯å¦é€’å½’æŸ¥è¯¢å­æ–‡ä»¶å¤¹ï¼Œé»˜è®¤ False
            include_pending: æ˜¯å¦åŒ…å«æœªå®Œæˆæ³¨å†Œçš„æ–‡ä»¶ï¼Œé»˜è®¤ False
            include_raw: æ˜¯å¦åŒ…å«å®Œæ•´çš„åŸå§‹å…ƒæ•°æ®ï¼Œé»˜è®¤ True
            media_status: æŒ‰åª’èµ„çŠ¶æ€è¿‡æ»¤ (completed/pending/failed)
            page: é¡µç ï¼ˆä»1å¼€å§‹ï¼‰ï¼Œç”¨äºåˆ†é¡µ
            page_size: æ¯é¡µå¤§å°ï¼Œç”¨äºåˆ†é¡µ
            
        Returns:
            Dict: åŒ…å«æ–‡ä»¶åŠåª’èµ„ä¿¡æ¯çš„å­—å…¸
        """
        try:
            # å°†ç”¨æˆ·æä¾›çš„ç›¸å¯¹è·¯å¾„ä¸ bucket_name æ‹¼æ¥
            full_path = self._build_full_path(folder_path)
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {
                "folder_path": full_path,
                "recursive": recursive,
                "include_pending": include_pending,
                "include_raw": include_raw
            }
            
            if media_status:
                params["media_status"] = media_status
            if page:
                params["page"] = page
            if page_size:
                params["page_size"] = page_size
            
            # è°ƒç”¨API
            response = await self.api_client.request(
                "GET",
                "/api/v1/folders/media-ids/by-path",
                params=params
            )
            
            data = response.json()
            
            log.info(
                "è·å–æ–‡ä»¶å¤¹ %s çš„åª’èµ„åˆ—è¡¨æˆåŠŸ: %s ä¸ªæ–‡ä»¶ (recursive=%s)",
                folder_path,
                data.get('stats', {}).get('total_files', 0),
                recursive
            )
            
            return data
            
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 404:
                log.error(
                    "æ–‡ä»¶å¤¹ä¸å­˜åœ¨: folder_path=%sã€‚"
                    "è¯·æ£€æŸ¥ï¼š1) æ–‡ä»¶å¤¹è·¯å¾„æ˜¯å¦æ­£ç¡® 2) æ–‡ä»¶å¤¹æ˜¯å¦å·²åˆ›å»º 3) è·¯å¾„æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆåº”ä»¥/ç»“å°¾ï¼‰",
                    folder_path
                )
            raise
        except Exception as e:
            log.error("è·å–æ–‡ä»¶å¤¹åª’èµ„åˆ—è¡¨å¤±è´¥: folder_path=%s, error=%s", folder_path, e)
            log.exception(e)
            raise
    
    async def get_folder_structure(
        self,
        moss_path: str,
        include_bucket: bool = False
    ) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶å¤¹çš„å±‚çº§ç»“æ„ï¼ˆåŒ…å«å­æ–‡ä»¶å¤¹å’Œæ–‡ä»¶åˆ—è¡¨ï¼‰
        
        é€šè¿‡æ–‡ä»¶å¤¹è·¯å¾„è·å–è¯¥æ–‡ä»¶å¤¹åŠå…¶æ‰€æœ‰å­æ–‡ä»¶å¤¹çš„æ ‘å½¢ç»“æ„ã€‚
        æ¯ä¸ªæ–‡ä»¶å¤¹åŒ…å«ç›´æ¥çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆä»…æ–‡ä»¶åï¼‰ã€‚
        
        Args:
            moss_path: ç›¸å¯¹è·¯å¾„ï¼Œä¸åŒ…å« bucket_name
            include_bucket: æ˜¯å¦åœ¨ç»“æ„ä¸­åŒ…å« bucket_name é¡¶çº§ç›®å½•ï¼Œé»˜è®¤ False
            
        Returns:
            Dict: åŒ…å«æ–‡ä»¶å¤¹ç»“æ„çš„å­—å…¸
        """
        try:
            # å°†ç”¨æˆ·æä¾›çš„ç›¸å¯¹è·¯å¾„ä¸ bucket_name æ‹¼æ¥
            full_path = self._build_full_path(moss_path)
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {
                "moss_path": full_path,
                "include_bucket": include_bucket
            }
            
            # è°ƒç”¨API
            response = await self.api_client.request(
                "GET",
                "/api/v1/folders/structure/by-path",
                params=params
            )
            
            data = response.json()
            
            log.info(
                "è·å–æ–‡ä»¶å¤¹ç»“æ„æˆåŠŸ: %s (æ€»å…± %s ä¸ªæ–‡ä»¶å¤¹, %s ä¸ªæ–‡ä»¶)",
                moss_path,
                data.get('total_folders', 0),
                data.get('total_files', 0)
            )
            
            return data
            
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 404:
                error_msg = (
                    f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: moss_path={moss_path}\n"
                    f"å¯èƒ½çš„åŸå› ï¼š\n"
                    f"  1. è·¯å¾„ä¸æ­£ç¡® - è¯·æ£€æŸ¥æ–‡ä»¶å¤¹åç§°æ˜¯å¦æ‹¼å†™æ­£ç¡®\n"
                    f"  2. æ–‡ä»¶å¤¹æœªåˆ›å»º - è¯¥æ–‡ä»¶å¤¹å¯èƒ½è¿˜ä¸å­˜åœ¨äºç³»ç»Ÿä¸­\n"
                    f"  3. è·¯å¾„æ ¼å¼é”™è¯¯ - è·¯å¾„åº”è¯¥ä»¥ / å¼€å¤´å’Œç»“å°¾ï¼Œå¦‚ '/updated_folder_176/'\n"
                )
                log.error(error_msg)
            raise
        except Exception as e:
            log.error("è·å–æ–‡ä»¶å¤¹ç»“æ„å¤±è´¥: moss_path=%s, error=%s", moss_path, e)
            log.exception(e)
            raise


    async def get_folder_contents(
        self,
        folder_id: int,
        page: int = 1,
        page_size: int = 100
    ) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶å¤¹å†…å®¹è¯¦æƒ…ï¼ˆåŒ…å« AI æ‰“æ ‡ç»“æœï¼‰
        
        é€šè¿‡ folder_id è·å–è¯¥æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ç´ æçš„è¯¦ç»†ä¿¡æ¯ï¼Œ
        åŒ…æ‹¬ AI å†…å®¹åˆ†æç»“æœï¼ˆæ ‡ç­¾ã€åœºæ™¯ã€æƒ…æ„Ÿç­‰ï¼‰å’Œæ—¶é•¿ä¿¡æ¯ã€‚
        
        Args:
            folder_id: æ–‡ä»¶å¤¹ ID
            page: é¡µç ï¼Œä» 1 å¼€å§‹
            page_size: æ¯é¡µæ•°é‡ï¼Œé»˜è®¤ 100
            
        Returns:
            Dict: åŒ…å«ç´ æè¯¦æƒ…çš„å“åº”
                - items: ç´ æåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å«ï¼š
                    - moss_id: ç´ æ ID
                    - file_name: æ–‡ä»¶å
                    - start_time/end_time: ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰
                    - content_analysis_result: AI æ‰“æ ‡ç»“æœ
                        - main_subject: ä¸»ä½“
                        - action_or_event: åŠ¨ä½œ/äº‹ä»¶
                        - scene_setting: åœºæ™¯
                        - visual_style: è§†è§‰é£æ ¼
                        - keywords: å…³é”®è¯åˆ—è¡¨
                        - atmosphere_tags: æ°›å›´æ ‡ç­¾
                        - emotion_dominant: ä¸»å¯¼æƒ…æ„Ÿ
                    - metadata: å…ƒæ•°æ®ï¼ˆåˆ†è¾¨ç‡ã€å¸§ç‡ç­‰ï¼‰
                - total: æ€»æ•°
                - page: å½“å‰é¡µ
                - page_size: æ¯é¡µæ•°é‡
                
        Examples:
            ```python
            result = await moss.get_folder_contents(folder_id=123)
            for item in result.get("items", []):
                print(f"ç´ æ: {item['file_name']}")
                analysis = item.get("content_analysis_result", {})
                print(f"  å…³é”®è¯: {analysis.get('keywords', [])}")
            ```
        """
        try:
            log.info(f"è·å–æ–‡ä»¶å¤¹å†…å®¹è¯¦æƒ…: folder_id={folder_id}, page={page}")
            
            response = await self.api_client.request(
                "GET",
                f"/api/v1/folders/{folder_id}/contents",
                params={
                    "page": page,
                    "page_size": page_size
                }
            )
            
            data = response.json()
            items = data.get("items", [])
            
            log.info(f"è·å–æ–‡ä»¶å¤¹å†…å®¹æˆåŠŸ: folder_id={folder_id}, å…± {len(items)} ä¸ªç´ æ")
            
            return data
            
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 404:
                log.error(f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: folder_id={folder_id}")
            raise
        except Exception as e:
            log.error(f"è·å–æ–‡ä»¶å¤¹å†…å®¹å¤±è´¥: folder_id={folder_id}, error={e}")
            raise

    async def batch_copy_from_oss(
        self,
        source_oss_folder_path: str,
        target_folder_path: str = "/"
    ) -> Dict[str, Any]:
        """æ‰¹é‡ä»å¤–éƒ¨OSSå¤åˆ¶æ–‡ä»¶åˆ°MOSS
        
        å¦‚æœç›®æ ‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºã€‚
        
        Args:
            source_oss_folder_path: æºOSSæ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ ¼å¼å¦‚ oss://bucket-name/path/
            target_folder_path: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ï¼Œé»˜è®¤ä¸ºæ ¹ç›®å½• "/"
                               å¦‚æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»º
            
        Returns:
            Dict: åŒ…å«ä»»åŠ¡IDå’ŒçŠ¶æ€çš„å“åº”
        """
        # é€šè¿‡è·¯å¾„è·å– folder_idï¼ˆè‡ªåŠ¨åˆ›å»ºä¸å­˜åœ¨çš„æ–‡ä»¶å¤¹ï¼‰
        target_folder_id = await self._get_folder_id_by_path(target_folder_path)
        
        log.info(f"æ‰¹é‡å¤åˆ¶ä»»åŠ¡ - æº: {source_oss_folder_path}, ç›®æ ‡: {target_folder_path} (ID: {target_folder_id})")
        
        response = await self.api_client.request(
            "POST",
            "/api/v1/oss-direct-upload/batch-copy-from-oss",
            json={
                "source_oss_path": source_oss_folder_path,  # åç«¯æ¥å£ä»ä½¿ç”¨ source_oss_path
                "target_folder_id": target_folder_id,
            },
        )
        return response.json()

    async def upload_from_url(
        self,
        url: str,
        folder_path: str = "/",
        tags: Optional[list] = None,
        enable_content_analysis: bool = False,
        frame_level: str = "medium"
    ) -> Dict[str, Any]:
        """é€šè¿‡URLä¸Šä¼ æ–‡ä»¶åˆ°MOSS
        
        æ”¯æŒä»URLç›´æ¥ä¸‹è½½è§†é¢‘ã€å›¾ç‰‡ã€éŸ³é¢‘æ–‡ä»¶å¹¶ä¸Šä¼ åˆ°MOSSç³»ç»Ÿã€‚
        ä½¿ç”¨å¼‚æ­¥æµå¼ä¸‹è½½ï¼Œé¿å…å†…å­˜å ç”¨è¿‡é«˜ã€‚
        å¦‚æœç›®æ ‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºã€‚
        
        Args:
            url: è¦ä¸‹è½½çš„æ–‡ä»¶URL
            folder_path: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ï¼Œé»˜è®¤ä¸ºæ ¹ç›®å½• "/"
                        å¦‚æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»º
            tags: æ–‡ä»¶æ ‡ç­¾åˆ—è¡¨ï¼Œå¯é€‰
            enable_content_analysis: æ˜¯å¦å¯ç”¨AIå†…å®¹åˆ†æï¼ˆä»…æ”¯æŒè§†é¢‘æ–‡ä»¶ï¼‰
            frame_level: æŠ½å¸§ç­‰çº§: low/medium/high
            
        Returns:
            Dict: åŒ…å«ä¸Šä¼ ç»“æœï¼ŒåŒ…æ‹¬ï¼š
                - success: æ˜¯å¦æˆåŠŸ
                - moss_id: MOSS ID
                - task_id: ä»»åŠ¡ID
                - message: æç¤ºä¿¡æ¯
                
        Examples:
            é€šè¿‡URLä¸Šä¼ æ–‡ä»¶ï¼š
            ```python
            result = await moss.upload_from_url(
                url="https://example.com/video.mp4"
            )
            print(f"ä¸Šä¼ æˆåŠŸ: {result['moss_id']}")
            ```
            
            ä¸Šä¼ åˆ°æŒ‡å®šæ–‡ä»¶å¤¹ï¼š
            ```python
            result = await moss.upload_from_url(
                url="https://example.com/image.jpg",
                folder_path="/images/"
            )
            print(f"ä¸Šä¼ æˆåŠŸ: {result['moss_id']}")
            ```
        """
        # é€šè¿‡è·¯å¾„è·å– folder_idï¼ˆè‡ªåŠ¨åˆ›å»ºä¸å­˜åœ¨çš„æ–‡ä»¶å¤¹ï¼‰
        folder_id = await self._get_folder_id_by_path(folder_path)
        
        log.info(f"ğŸš€ å¼€å§‹URLä¸Šä¼ ä»»åŠ¡ - URL: {url}, ç›®æ ‡: {folder_path} (ID: {folder_id})")
        
        # è°ƒç”¨æ‰¹é‡å¤åˆ¶APIçš„URLæ¨¡å¼
        request_data = {
            "url": url,
            "target_folder_id": folder_id,
            "tags": tags or [],
            "enable_content_analysis": enable_content_analysis,
            "frame_level": frame_level
        }
        
        response = await self.api_client.request(
            "POST",
            "/api/v1/oss-direct-upload/batch-copy-from-oss",
            json=request_data
        )
        
        result = response.json()
        
        if result.get("success"):
            log.info(f"âœ… URLä¸Šä¼ ä»»åŠ¡å·²å¯åŠ¨ - Task ID: {result['task_id']}")
            return {
                "success": True,
                "task_id": result["task_id"],
                "message": result.get("message", "URLä¸Šä¼ ä»»åŠ¡å·²å¯åŠ¨")
            }
        else:
            log.error(f"âŒ URLä¸Šä¼ å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
            return {
                "success": False,
                "message": result.get("message", "URLä¸Šä¼ å¤±è´¥")
            }

    async def list_batch_copy_tasks(
        self,
        status_filter: Optional[str] = None,
        limit: int = 100,
        offset: int = 0,
    ) -> Dict[str, Any]:
        params: Dict[str, Any] = {"limit": limit, "offset": offset}
        if status_filter:
            params["status_filter"] = status_filter
        response = await self.api_client.request(
            "GET",
            "/api/v1/oss-direct-upload/batch-copy-tasks",
            params=params,
        )
        return response.json()

    async def create_script_variation_task(
        self,
        script: str,
        title: str,
        variation_count: int = 3,
        level: str = "medium",
        special_requirements: Optional[str] = None
    ) -> Dict[str, Any]:
        """åˆ›å»ºè„šæœ¬è£‚å˜ä»»åŠ¡
        
        Args:
            script: åŸå§‹è„šæœ¬å†…å®¹
            title: è„šæœ¬æ ‡é¢˜
            variation_count: è£‚å˜æ•°é‡ï¼Œé»˜è®¤3
            level: è£‚å˜ç­‰çº§ (low/medium/high)ï¼Œé»˜è®¤ medium
            special_requirements: ç‰¹æ®Šè¦æ±‚ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Dict: åŒ…å«ä»»åŠ¡IDå’ŒçŠ¶æ€çš„å“åº”
        """
        payload = {
            "script": script,
            "title": title,
            "variation_count": variation_count,
            "level": level
        }
        if special_requirements:
            payload["special_requirements"] = special_requirements
        
        log.info(f"ğŸ¬ åˆ›å»ºè„šæœ¬è£‚å˜ä»»åŠ¡: title={title}, count={variation_count}, level={level}")
        
        response = await self.api_client.request(
            "POST",
            "/api/v1/script-variation/tasks",
            json=payload
        )
        return response.json()

    async def create_copy_variation_task(
        self,
        script: str,
        title: str,
        variation_count: int = 3,
        level: str = "medium",
        special_requirements: Optional[str] = None
    ) -> Dict[str, Any]:
        """åˆ›å»ºæ–‡æ¡ˆè£‚å˜ä»»åŠ¡
        
        Args:
            script: åŸå§‹æ–‡æ¡ˆå†…å®¹
            title: æ–‡æ¡ˆæ ‡é¢˜
            variation_count: è£‚å˜æ•°é‡ï¼Œé»˜è®¤3
            level: è£‚å˜ç­‰çº§ (low/medium/high)ï¼Œé»˜è®¤ medium
            special_requirements: ç‰¹æ®Šè¦æ±‚ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Dict: åŒ…å«ä»»åŠ¡IDå’ŒçŠ¶æ€çš„å“åº”
        """
        payload = {
            "script": script,
            "title": title,
            "variation_count": variation_count,
            "level": level
        }
        if special_requirements:
            payload["special_requirements"] = special_requirements
        
        log.info(f"ğŸ“ åˆ›å»ºæ–‡æ¡ˆè£‚å˜ä»»åŠ¡: title={title}, count={variation_count}, level={level}")
        
        response = await self.api_client.request(
            "POST",
            "/api/v1/copy-variation/tasks",
            json=payload
        )
        return response.json()

    async def query_variation_tasks(
        self,
        variation_type: str = "script",
        shot_matching_task_id: Optional[str] = None,
        variation_task_id: Optional[str] = None,
        page: int = 1,
        page_size: int = 20
    ) -> Dict[str, Any]:
        """æŸ¥è¯¢è£‚å˜ä»»åŠ¡
        
        Args:
            variation_type: è£‚å˜ç±»å‹ (script/copy)
            shot_matching_task_id: é•œå¤´ç»„ä»»åŠ¡IDï¼ˆå¯é€‰ï¼Œæä¾›æ—¶è¿”å›è¯¥é•œå¤´ç»„çš„æ‰€æœ‰è£‚å˜æ–‡æ¡ˆï¼‰
            variation_task_id: è£‚å˜ä»»åŠ¡IDï¼ˆå¯é€‰ï¼Œæä¾›æ—¶åœ¨å®¢æˆ·ç«¯ä¾§ç­›é€‰ç‰¹å®šä»»åŠ¡ï¼‰
            page: é¡µç ï¼Œä»1å¼€å§‹
            page_size: æ¯é¡µæ•°é‡ï¼Œé»˜è®¤20ï¼Œæœ€å¤§100
            
        Returns:
            Dict: åŒ…å«ä»»åŠ¡åˆ—è¡¨çš„å“åº”
        """
        params: Dict[str, Any] = {
            "type": variation_type,
            "page": page,
            "page_size": min(page_size, 100)
        }
        if shot_matching_task_id:
            params["shot_matching_task_id"] = shot_matching_task_id
        
        log.info(f"ğŸ” æŸ¥è¯¢è£‚å˜ä»»åŠ¡: type={variation_type}, page={page}")
        
        response = await self.api_client.request(
            "GET",
            "/api/v1/script-variation/tasks",
            params=params
        )
        result = response.json()
        
        # å®¢æˆ·ç«¯ä¾§ç­›é€‰ï¼šå¦‚æœæä¾›äº† variation_task_idï¼Œç­›é€‰ç‰¹å®šä»»åŠ¡
        if variation_task_id and result.get("tasks"):
            filtered_tasks = [t for t in result["tasks"] if t.get("task_id") == variation_task_id]
            result["tasks"] = filtered_tasks
            result["total"] = len(filtered_tasks)
        
        return result

    async def get_direct_download_url(
        self,
        oss_path: str,
        bucket_name: Optional[str] = None,
        expire_seconds: int = 300
    ) -> Dict[str, Any]:
        """è·å–OSSæ–‡ä»¶çš„ç›´æ¥ä¸‹è½½URL
        
        é€šè¿‡MOSS APIè·å–OSSæ–‡ä»¶çš„é¢„ç­¾åä¸‹è½½URLã€‚
        
        Args:
            oss_path: OSSæ–‡ä»¶è·¯å¾„ï¼ˆä¸å¸¦å¼€å¤´æ–œæ ï¼‰ï¼Œä¾‹å¦‚ "MUSE/Dev/20251218/xlsx/"
            bucket_name: OSS Bucketåç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„ bucket_name
            expire_seconds: URLè¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤300ï¼ŒèŒƒå›´60-86400
            
        Returns:
            Dict: åŒ…å«ä¸‹è½½URLçš„å“åº”
                - success: æ˜¯å¦æˆåŠŸ
                - url: é¢„ç­¾åä¸‹è½½URL
                - bucket_name: Bucketåç§°
                - oss_path: æ–‡ä»¶è·¯å¾„
                - expires_at: URLè¿‡æœŸæ—¶é—´
                - message: æç¤ºä¿¡æ¯
                
        Examples:
            è·å–Excelæ–‡ä»¶ä¸‹è½½URLï¼š
            ```python
            result = await moss.get_direct_download_url(
                oss_path="MUSE/Dev/20251218/xlsx/video-info.xlsx"
            )
            if result.get("success"):
                print(f"ä¸‹è½½URL: {result['url']}")
            ```
        """
        try:
            # ä½¿ç”¨ä¼ å…¥çš„bucket_nameæˆ–é…ç½®ä¸­çš„bucket_name
            target_bucket = bucket_name or self.config.bucket_name
            
            # ç¡®ä¿oss_pathä¸ä»¥æ–œæ å¼€å¤´
            if oss_path.startswith("/"):
                oss_path = oss_path[1:]
            
            # éªŒè¯expire_secondsèŒƒå›´
            expire_seconds = max(60, min(86400, expire_seconds))
            
            log.info(f"ğŸ“¥ è·å–ç›´æ¥ä¸‹è½½URL: bucket={target_bucket}, path={oss_path}")
            log.info(f"ğŸ“¥ è¯·æ±‚URL: {self.api_client.config.base_url}/api/v1/oss/direct-url")
            
            request_body = {
                "bucket_name": target_bucket,
                "oss_path": oss_path,
                "expire_seconds": expire_seconds
            }
            log.info(f"ğŸ“¥ è¯·æ±‚ä½“: {request_body}")
            
            response = await self.api_client.request(
                "POST",
                "/api/v1/oss/direct-url",
                json=request_body
            )
            
            data = response.json()
            
            is_folder = data.get("is_folder", False)
            file_count = data.get("file_count", 1)
            
            log.info(f"âœ… è·å–ä¸‹è½½URLæˆåŠŸ: {oss_path}, is_folder={is_folder}, file_count={file_count}")
            
            return {
                "success": True,
                "url": data.get("url"),
                "bucket_name": data.get("bucket_name"),
                "oss_path": data.get("oss_path"),
                "is_folder": is_folder,
                "files": data.get("files"),
                "file_count": file_count,
                "expires_at": data.get("expires_at"),
                "message": data.get("message", "è·å–ä¸‹è½½URLæˆåŠŸ")
            }
            
        except httpx.HTTPStatusError as e:
            error_detail = "æœªçŸ¥é”™è¯¯"
            try:
                error_data = e.response.json()
                error_detail = error_data.get("detail", str(e))
            except:
                error_detail = e.response.text or str(e)
            
            # å°†å¸¸è§çš„è‹±æ–‡é”™è¯¯ä¿¡æ¯ç¿»è¯‘ä¸ºä¸­æ–‡
            if "not found" in error_detail.lower() or "Not Found" in error_detail:
                error_detail = f"æ–‡ä»¶æœªæ‰¾åˆ°: {oss_path}"
            elif "unauthorized" in error_detail.lower():
                error_detail = "è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ Access Key é…ç½®"
            elif "forbidden" in error_detail.lower():
                error_detail = "æƒé™ä¸è¶³ï¼Œæ— æ³•è®¿é—®è¯¥æ–‡ä»¶"
            elif "File not found" in error_detail:
                error_detail = f"æ–‡ä»¶æœªæ‰¾åˆ°: {oss_path}"
            
            log.error(f"âŒ è·å–ä¸‹è½½URLå¤±è´¥: {error_detail}")
            return {
                "success": False,
                "message": error_detail
            }
        except Exception as e:
            log.error(f"âŒ è·å–ä¸‹è½½URLå¤±è´¥: {e}")
            return {
                "success": False,
                "message": str(e)
            }

    async def get_download_url_by_moss_id(
        self,
        moss_id: str,
        expire_seconds: int = 3600
    ) -> Dict[str, Any]:
        """é€šè¿‡ MOSS ID è·å–æ–‡ä»¶ä¸‹è½½ URL
        
        ä½¿ç”¨ MOSS API ç›´æ¥é€šè¿‡ moss_id è·å–é¢„ç­¾åä¸‹è½½ URLï¼Œæ— éœ€å…ˆè·å– oss_pathã€‚
        
        Args:
            moss_id: MOSS æ–‡ä»¶ ID
            expire_seconds: URL è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 3600ï¼ŒèŒƒå›´ 60-86400
            
        Returns:
            Dict: åŒ…å«ä¸‹è½½ URL çš„å“åº”
                - success: æ˜¯å¦æˆåŠŸ
                - url: é¢„ç­¾åä¸‹è½½ URL
                - expires_at: URL è¿‡æœŸæ—¶é—´
                - message: æç¤ºä¿¡æ¯
                
        Examples:
            ```python
            result = await moss.get_download_url_by_moss_id(
                moss_id="15ba56b0-47f0-4376-af92-514acdc2d0c7"
            )
            if result.get("success"):
                print(f"ä¸‹è½½URL: {result['url']}")
            ```
        """
        try:
            # éªŒè¯ expire_seconds èŒƒå›´
            expire_seconds = max(60, min(86400, expire_seconds))
            
            log.info(f"ğŸ“¥ é€šè¿‡ MOSS ID è·å–ä¸‹è½½ URL: moss_id={moss_id}")
            
            response = await self.api_client.request(
                "GET",
                f"/api/v1/oss/url/{moss_id}",
                params={"expire_seconds": expire_seconds}
            )
            
            data = response.json()
            
            log.info(f"âœ… è·å–ä¸‹è½½ URL æˆåŠŸ: moss_id={moss_id}")
            
            return {
                "success": True,
                "url": data.get("url"),
                "expires_at": data.get("expires_at"),
                "message": "è·å–ä¸‹è½½ URL æˆåŠŸ"
            }
            
        except httpx.HTTPStatusError as e:
            error_detail = "æœªçŸ¥é”™è¯¯"
            try:
                error_data = e.response.json()
                error_detail = error_data.get("message") or error_data.get("detail", str(e))
            except:
                error_detail = e.response.text or str(e)
            
            # ç¿»è¯‘å¸¸è§é”™è¯¯ä¿¡æ¯
            if "not found" in error_detail.lower():
                error_detail = f"æ–‡ä»¶æœªæ‰¾åˆ°: {moss_id}"
            elif "unauthorized" in error_detail.lower():
                error_detail = "è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ Access Key é…ç½®"
            elif "forbidden" in error_detail.lower() or "access denied" in error_detail.lower():
                error_detail = "æƒé™ä¸è¶³ï¼Œæ— æ³•è®¿é—®è¯¥æ–‡ä»¶"
            
            log.error(f"âŒ è·å–ä¸‹è½½ URL å¤±è´¥: {error_detail}")
            return {
                "success": False,
                "message": error_detail
            }
        except Exception as e:
            log.error(f"âŒ è·å–ä¸‹è½½ URL å¤±è´¥: {e}")
            return {
                "success": False,
                "message": str(e)
            }



# ===== åŒæ­¥æ¥å£åŒ…è£…å™¨ =====

class MossProUtilsSync:
    """Moss Pro å·¥å…·çš„åŒæ­¥æ¥å£ - ä½¿ç”¨æ˜æ–‡ AKSK è®¤è¯"""
    
    def __init__(self, config: MossConfig):
        self.config = config
    
    def upload_file(
        self,
        file_path: str,
        folder_path: str = "/",
        tags: Optional[list] = None,
        progress_callback: Optional[Callable[[int, int], None]] = None,
        enable_content_analysis: bool = False,
        frame_level: str = "medium"
    ) -> Dict[str, Any]:
        """åŒæ­¥ä¸Šä¼ æ–‡ä»¶åˆ° MOSS
        
        å¦‚æœç›®æ ‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºã€‚
        
        Args:
            file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            folder_path: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ï¼Œé»˜è®¤ä¸ºæ ¹ç›®å½•
                        å¦‚æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»º
            tags: æ–‡ä»¶æ ‡ç­¾åˆ—è¡¨ï¼Œå¯é€‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            enable_content_analysis: æ˜¯å¦å¯ç”¨AIå†…å®¹åˆ†æ
            frame_level: æŠ½å¸§ç­‰çº§
            
        Returns:
            Dict: åŒ…å«ä¸Šä¼ ç»“æœ
        """
        async def _upload():
            moss_pro = MossProUtils(self.config)
            async with moss_pro as client:
                return await client.upload_file(
                    file_path, folder_path, tags, progress_callback,
                    enable_content_analysis, frame_level
                )
        
        return asyncio.run(_upload())
    
    def get_folder_media_ids(
        self,
        folder_path: str,
        recursive: bool = False,
        include_pending: bool = False,
        include_raw: bool = True,
        media_status: Optional[str] = None,
        page: Optional[int] = None,
        page_size: Optional[int] = None
    ) -> Dict[str, Any]:
        """åŒæ­¥è·å–æ–‡ä»¶å¤¹åª’èµ„IDåˆ—è¡¨"""
        async def _get_media_ids():
            moss_pro = MossProUtils(self.config)
            async with moss_pro as client:
                return await client.get_folder_media_ids(
                    folder_path, recursive, include_pending, include_raw,
                    media_status, page, page_size
                )
        
        return asyncio.run(_get_media_ids())
    
    def upload_from_url(
        self,
        url: str,
        folder_path: str = "/",
        tags: Optional[list] = None,
        enable_content_analysis: bool = False,
        frame_level: str = "medium"
    ) -> Dict[str, Any]:
        """åŒæ­¥é€šè¿‡URLä¸Šä¼ æ–‡ä»¶åˆ°MOSS
        
        Args:
            url: è¦ä¸‹è½½çš„æ–‡ä»¶URL
            folder_path: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ï¼Œé»˜è®¤ä¸ºæ ¹ç›®å½• "/"
                        å¦‚æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»º
            tags: æ–‡ä»¶æ ‡ç­¾åˆ—è¡¨ï¼Œå¯é€‰
            enable_content_analysis: æ˜¯å¦å¯ç”¨AIå†…å®¹åˆ†æ
            frame_level: æŠ½å¸§ç­‰çº§
            
        Returns:
            Dict: åŒ…å«ä¸Šä¼ ç»“æœ
        """
        async def _upload():
            moss_pro = MossProUtils(self.config)
            async with moss_pro as client:
                return await client.upload_from_url(
                    url, folder_path, tags,
                    enable_content_analysis, frame_level
                )
        
        return asyncio.run(_upload())

    def get_folder_structure(
        self,
        moss_path: str,
        include_bucket: bool = False
    ) -> Dict[str, Any]:
        """åŒæ­¥è·å–æ–‡ä»¶å¤¹å±‚çº§ç»“æ„"""
        async def _get_structure():
            moss_pro = MossProUtils(self.config)
            async with moss_pro as client:
                return await client.get_folder_structure(moss_path, include_bucket)
        
        return asyncio.run(_get_structure())

    def get_folder_contents(
        self,
        folder_id: int,
        page: int = 1,
        page_size: int = 100
    ) -> Dict[str, Any]:
        """åŒæ­¥è·å–æ–‡ä»¶å¤¹å†…å®¹è¯¦æƒ…ï¼ˆåŒ…å« AI æ‰“æ ‡ç»“æœï¼‰
        
        Args:
            folder_id: æ–‡ä»¶å¤¹ ID
            page: é¡µç ï¼Œä» 1 å¼€å§‹
            page_size: æ¯é¡µæ•°é‡
            
        Returns:
            Dict: åŒ…å«ç´ æè¯¦æƒ…çš„å“åº”
        """
        async def _get_contents():
            moss_pro = MossProUtils(self.config)
            async with moss_pro as client:
                return await client.get_folder_contents(folder_id, page, page_size)
        
        return asyncio.run(_get_contents())

    def batch_copy_from_oss(
        self,
        source_oss_folder_path: str,
        target_folder_path: str = "/"
    ) -> Dict[str, Any]:
        """åŒæ­¥æ‰¹é‡ä»å¤–éƒ¨OSSå¤åˆ¶æ–‡ä»¶
        
        Args:
            source_oss_folder_path: æºOSSæ–‡ä»¶å¤¹è·¯å¾„
            target_folder_path: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ï¼Œé»˜è®¤ä¸ºæ ¹ç›®å½• "/"
                               å¦‚æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»º
        """
        async def _start():
            moss_pro = MossProUtils(self.config)
            async with moss_pro as client:
                return await client.batch_copy_from_oss(
                    source_oss_folder_path=source_oss_folder_path,
                    target_folder_path=target_folder_path
                )
        return asyncio.run(_start())

    def list_batch_copy_tasks(
        self,
        status_filter: Optional[str] = None,
        limit: int = 100,
        offset: int = 0,
    ) -> Dict[str, Any]:
        async def _list():
            moss_pro = MossProUtils(self.config)
            async with moss_pro as client:
                return await client.list_batch_copy_tasks(
                    status_filter=status_filter,
                    limit=limit,
                    offset=offset,
                )
        return asyncio.run(_list())

    def create_script_variation_task(
        self,
        script: str,
        title: str,
        variation_count: int = 3,
        level: str = "medium",
        special_requirements: Optional[str] = None
    ) -> Dict[str, Any]:
        """åŒæ­¥åˆ›å»ºè„šæœ¬è£‚å˜ä»»åŠ¡
        
        Args:
            script: åŸå§‹è„šæœ¬å†…å®¹
            title: è„šæœ¬æ ‡é¢˜
            variation_count: è£‚å˜æ•°é‡
            level: è£‚å˜ç­‰çº§ (low/medium/high)
            special_requirements: ç‰¹æ®Šè¦æ±‚ï¼ˆå¯é€‰ï¼‰
        """
        async def _create():
            moss_pro = MossProUtils(self.config)
            async with moss_pro as client:
                return await client.create_script_variation_task(
                    script=script,
                    title=title,
                    variation_count=variation_count,
                    level=level,
                    special_requirements=special_requirements
                )
        return asyncio.run(_create())

    def create_copy_variation_task(
        self,
        script: str,
        title: str,
        variation_count: int = 3,
        level: str = "medium",
        special_requirements: Optional[str] = None
    ) -> Dict[str, Any]:
        """åŒæ­¥åˆ›å»ºæ–‡æ¡ˆè£‚å˜ä»»åŠ¡
        
        Args:
            script: åŸå§‹æ–‡æ¡ˆå†…å®¹
            title: æ–‡æ¡ˆæ ‡é¢˜
            variation_count: è£‚å˜æ•°é‡
            level: è£‚å˜ç­‰çº§ (low/medium/high)
            special_requirements: ç‰¹æ®Šè¦æ±‚ï¼ˆå¯é€‰ï¼‰
        """
        async def _create():
            moss_pro = MossProUtils(self.config)
            async with moss_pro as client:
                return await client.create_copy_variation_task(
                    script=script,
                    title=title,
                    variation_count=variation_count,
                    level=level,
                    special_requirements=special_requirements
                )
        return asyncio.run(_create())

    def query_variation_tasks(
        self,
        variation_type: str = "script",
        shot_matching_task_id: Optional[str] = None,
        variation_task_id: Optional[str] = None,
        page: int = 1,
        page_size: int = 20
    ) -> Dict[str, Any]:
        """åŒæ­¥æŸ¥è¯¢è£‚å˜ä»»åŠ¡
        
        Args:
            variation_type: è£‚å˜ç±»å‹ (script/copy)
            shot_matching_task_id: é•œå¤´ç»„ä»»åŠ¡IDï¼ˆå¯é€‰ï¼Œç”¨äºæŸ¥è¯¢ä¸é•œå¤´ç»„å…³è”çš„è£‚å˜ä»»åŠ¡ï¼‰
            variation_task_id: è£‚å˜ä»»åŠ¡IDï¼ˆå¯é€‰ï¼Œç”¨äºåœ¨å®¢æˆ·ç«¯ä¾§ç­›é€‰ç‰¹å®šä»»åŠ¡ï¼‰
            page: é¡µç 
            page_size: æ¯é¡µæ•°é‡
        """
        async def _query():
            moss_pro = MossProUtils(self.config)
            async with moss_pro as client:
                return await client.query_variation_tasks(
                    variation_type=variation_type,
                    shot_matching_task_id=shot_matching_task_id,
                    variation_task_id=variation_task_id,
                    page=page,
                    page_size=page_size
                )
        return asyncio.run(_query())

    def get_direct_download_url(
        self,
        oss_path: str,
        bucket_name: Optional[str] = None,
        expire_seconds: int = 3600
    ) -> Dict[str, Any]:
        """åŒæ­¥è·å–OSSæ–‡ä»¶çš„ç›´æ¥ä¸‹è½½URL
        
        Args:
            oss_path: OSSæ–‡ä»¶è·¯å¾„ï¼ˆä¸å¸¦å¼€å¤´æ–œæ ï¼‰
            bucket_name: OSS Bucketåç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„bucket_name
            expire_seconds: URLè¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤3600
            
        Returns:
            Dict: åŒ…å«ä¸‹è½½URLçš„å“åº”
        """
        async def _get_url():
            moss_pro = MossProUtils(self.config)
            async with moss_pro as client:
                return await client.get_direct_download_url(
                    oss_path=oss_path,
                    bucket_name=bucket_name,
                    expire_seconds=expire_seconds
                )
        return asyncio.run(_get_url())


# ===== ä¾¿æ·çš„å·¥å‚å‡½æ•° =====

def create_moss_pro_utils(
    base_url: Optional[str] = None,
    access_key_id: Optional[str] = None,
    access_key_secret: Optional[str] = None,
    bucket_name: Optional[str] = None,
    **kwargs
) -> MossProUtilsSync:
    """åˆ›å»º Moss Pro å·¥å…·å®ä¾‹ - ä½¿ç”¨æ˜æ–‡ AKSK è®¤è¯
    
    Args:
        base_url: Moss API æœåŠ¡åœ°å€ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡ MOSS_BASE_URL è¯»å–
        access_key_id: è®¿é—®å¯†é’¥ IDï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡ MOSS_ACCESS_KEY_ID è¯»å–
        access_key_secret: è®¿é—®å¯†é’¥ Secretï¼ˆæ˜æ–‡ï¼‰ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡ MOSS_ACCESS_KEY_SECRET è¯»å–
        bucket_name: Bucket åç§°ï¼ˆä¼ä¸šæ ‡è¯†ï¼‰ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡ MOSS_BUCKET_NAME è¯»å–
        **kwargs: å…¶ä»–é…ç½®å‚æ•°
        
    Returns:
        MossProUtilsSync: Moss Pro å·¥å…·åŒæ­¥æ¥å£å®ä¾‹
        
    Examples:
        åŸºæœ¬ä½¿ç”¨ï¼š
        ```python
        moss = create_moss_pro_utils(
            base_url="http://localhost:8000",
            access_key_id="YOUR_ACCESS_KEY_ID",
            access_key_secret="YOUR_ACCESS_KEY_SECRET",
            bucket_name="Dev"
        )
        
        # ä¸Šä¼ æ–‡ä»¶
        result = moss.upload_file(
            file_path="/path/to/video.mp4",
            folder_path="/"
        )
        print(f"ä¸Šä¼ æˆåŠŸ: {result['moss_id']}")
        
        # æŸ¥è¯¢æ–‡ä»¶å¤¹åª’èµ„
        result = moss.get_folder_media_ids(
            folder_path="/",
            recursive=False
        )
        ```
    """
    config = MossConfig(
        base_url=base_url,
        access_key_id=access_key_id,
        access_key_secret=access_key_secret,
        bucket_name=bucket_name,
        **kwargs
    )
    return MossProUtilsSync(config)


if __name__ == "__main__":
    # ===== ä½¿ç”¨ç¤ºä¾‹ =====
    import asyncio
    
    # å¼‚æ­¥ä½¿ç”¨ç¤ºä¾‹
    async def example_usage():
        """å¼‚æ­¥APIä½¿ç”¨ç¤ºä¾‹ - æ–‡ä»¶ä¸Šä¼  + åª’èµ„æŸ¥è¯¢"""
        config = MossConfig(
            base_url="http://localhost:8001",
            access_key_id="YOUR_ACCESS_KEY_ID",
            access_key_secret="YOUR_ACCESS_KEY_SECRET",
            bucket_name="YOUR_BUCKET_NAME"
        )
        
        async with MossProUtils(config) as moss:
            # ç¤ºä¾‹1: ä¸Šä¼ æ–‡ä»¶ï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰
            log.info("=== ç¤ºä¾‹1: ä¸Šä¼ æ–‡ä»¶ ===")
            
            def on_progress(uploaded, total):
                percent = (uploaded / total) * 100
                log.info(f"ä¸Šä¼ è¿›åº¦: {percent:.1f}% ({uploaded / 1024 / 1024:.2f} MB / {total / 1024 / 1024:.2f} MB)")
            
            try:
                result = await moss.upload_file(
                    file_path="/path/to/your/file.mp4",
                    folder_path="/",
                    tags=["test", "video"],
                    progress_callback=on_progress
                )
                
                if result.get("success"):
                    log.info(f"âœ… ä¸Šä¼ æˆåŠŸ - MOSS ID: {result['moss_id']}")
                else:
                    log.debug(f"ğŸ“¦ MOSS å¤ç”¨å·²æœ‰æ–‡ä»¶: {result.get('message')}")
            except Exception as e:
                log.error(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")
            
            # ç¤ºä¾‹2: è·å–æ–‡ä»¶å¤¹åª’èµ„åˆ—è¡¨
            log.info("=== ç¤ºä¾‹2: è·å–æ–‡ä»¶å¤¹åª’èµ„åˆ—è¡¨ ===")
            try:
                result = await moss.get_folder_media_ids(
                    folder_path="/",
                    recursive=False
                )
                log.info(f"æ€»æ–‡ä»¶æ•°: {result['stats']['total_files']}")
            except Exception as e:
                log.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
    
    # åŒæ­¥ä½¿ç”¨ç¤ºä¾‹
    def sync_example():
        """åŒæ­¥APIä½¿ç”¨ç¤ºä¾‹ - æ–‡ä»¶ä¸Šä¼ """
        moss = create_moss_pro_utils(
            base_url="http://localhost:8000",
            access_key_id="YOUR_ACCESS_KEY_ID",
            access_key_secret="YOUR_ACCESS_KEY_SECRET",
            bucket_name="YOUR_BUCKET_NAME"
        )
        
        log.info("=== åŒæ­¥APIç¤ºä¾‹: ä¸Šä¼ æ–‡ä»¶ ===")
        
        def on_progress(uploaded, total):
            percent = (uploaded / total) * 100
            print(f"\rä¸Šä¼ è¿›åº¦: {percent:.1f}%", end="", flush=True)
        
        try:
            result = moss.upload_file(
                file_path="/path/to/your/file.mp4",
                folder_path="/",
                progress_callback=on_progress
            )
            
            if result.get("success"):
                print(f"\nâœ… ä¸Šä¼ æˆåŠŸ - MOSS ID: {result['moss_id']}")
            else:
                print(f"\nâš ï¸ {result.get('message')}")
        except Exception as e:
            print(f"\nâŒ ä¸Šä¼ å¤±è´¥: {e}")
    
    log.info("=" * 60)
    log.info("MOSS Pro SDK - æ–‡ä»¶ä¸Šä¼ å’Œåª’èµ„ç®¡ç†å·¥å…·")
    log.info("ç‰¹æ€§: æ–‡ä»¶ä¸Šä¼  | OSSç›´ä¼  | åˆ†ç‰‡ä¸Šä¼  | åª’èµ„æŸ¥è¯¢ | AKSKè®¤è¯")
    log.info("è¿è¡Œç¤ºä¾‹: asyncio.run(example_usage()) æˆ– sync_example()")
    log.info("=" * 60)

