"""
å‘½ä»¤è¡Œæ¥å£
"""

import argparse
import json
import logging
import os
import platform
import shutil
import subprocess
import sys
import threading
import warnings
from pathlib import Path
from typing import List, Optional, Union

# å±è”½ Python ç‰ˆæœ¬ç›¸å…³çš„ FutureWarningï¼ˆGoogle åº“ä¼šè­¦å‘Š Python 3.9 å·²è¿‡æœŸï¼‰
warnings.filterwarnings("ignore", category=FutureWarning, module="google")
warnings.filterwarnings("ignore", message=".*Python version.*")
warnings.filterwarnings("ignore", message=".*end of life.*")

from .api_client import APIClient
from .config import ConfigManager
from .engine import GenerationEngine
from .exceptions import GeneratorError
from .gcs_uploader import GCSUploader
from .image_selector import ImageSelector
from .midjourney_client import MidjourneyClient
from .moss_uploader import MOSSUploader
from .openrouter_image_client import OpenRouterImageClient
from .output_manager import OutputManager
from .seedream_client import SeedreamClient
from .state_manager import StateManager
from .template_engine import TemplateEngine
from .text_generator import TextGenerator


def check_gcs_dependencies() -> bool:
    """
    æ£€æŸ¥ GCS ç›¸å…³ä¾èµ–æ˜¯å¦å·²å®‰è£…
    
    Returns:
        True å¦‚æœæ‰€æœ‰ä¾èµ–éƒ½å·²å®‰è£…
    """
    # æ£€æŸ¥ google-cloud-storage Python åŒ…
    try:
        import google.cloud.storage
        return True
    except ImportError:
        return False


def check_gcloud_auth() -> bool:
    """
    æ£€æŸ¥æ˜¯å¦å·²é€šè¿‡ gcloud ç™»å½•
    
    Returns:
        True å¦‚æœå·²ç™»å½•
    """
    # æ£€æŸ¥åº”ç”¨é»˜è®¤å‡­è¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    home = Path.home()
    adc_path = home / ".config" / "gcloud" / "application_default_credentials.json"
    
    if adc_path.exists():
        return True
    
    # Windows è·¯å¾„
    adc_path_win = home / "AppData" / "Roaming" / "gcloud" / "application_default_credentials.json"
    if adc_path_win.exists():
        return True
    
    return False


def install_gcs_dependencies():
    """å®‰è£… GCS ç›¸å…³ä¾èµ–"""
    print("ğŸ“¦ æ­£åœ¨å®‰è£… google-cloud-storage...")
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "google-cloud-storage"])
        print("âœ… google-cloud-storage å®‰è£…æˆåŠŸ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ å®‰è£…å¤±è´¥: {e}")
        return False


def install_gcloud_cli():
    """å®‰è£… gcloud CLI"""
    system = platform.system()
    
    if system == "Darwin":  # macOS
        # æ£€æŸ¥æ˜¯å¦æœ‰ brew
        if shutil.which("brew"):
            print("ğŸ“¦ æ­£åœ¨é€šè¿‡ Homebrew å®‰è£… google-cloud-sdk...")
            try:
                subprocess.check_call(["brew", "install", "google-cloud-sdk"])
                
                # Homebrew å®‰è£…åéœ€è¦æ·»åŠ  PATH
                gcloud_bin = "/opt/homebrew/share/google-cloud-sdk/bin"
                if os.path.exists(gcloud_bin):
                    # æ·»åŠ åˆ°å½“å‰è¿›ç¨‹çš„ PATH
                    os.environ["PATH"] = f"{gcloud_bin}:{os.environ.get('PATH', '')}"
                    
                    # æ·»åŠ åˆ° shell é…ç½®æ–‡ä»¶
                    shell_rc = Path.home() / ".zshrc"
                    if not shell_rc.exists():
                        shell_rc = Path.home() / ".bashrc"
                    
                    export_line = f'export PATH="{gcloud_bin}:$PATH"'
                    
                    # æ£€æŸ¥æ˜¯å¦å·²æ·»åŠ 
                    if shell_rc.exists():
                        content = shell_rc.read_text()
                        if gcloud_bin not in content:
                            with open(shell_rc, "a") as f:
                                f.write(f"\n# Google Cloud SDK\n{export_line}\n")
                            print(f"âœ… å·²æ·»åŠ  gcloud åˆ° PATH ({shell_rc.name})")
                    
                print("âœ… google-cloud-sdk å®‰è£…æˆåŠŸ")
                return True
            except subprocess.CalledProcessError:
                pass
        
        print("âŒ è¯·æ‰‹åŠ¨å®‰è£… gcloud CLI:")
        print("   brew install google-cloud-sdk")
        print("   æˆ–è®¿é—®: https://cloud.google.com/sdk/docs/install")
        return False
    
    elif system == "Linux":
        print("âŒ è¯·æ‰‹åŠ¨å®‰è£… gcloud CLI:")
        print("   curl https://sdk.cloud.google.com | bash")
        print("   æˆ–è®¿é—®: https://cloud.google.com/sdk/docs/install")
        return False
    
    elif system == "Windows":
        print("âŒ è¯·æ‰‹åŠ¨å®‰è£… gcloud CLI:")
        print("   è®¿é—®: https://cloud.google.com/sdk/docs/install")
        return False
    
    return False


def setup_gcs_auth():
    """è®¾ç½® GCS è®¤è¯"""
    print("\nğŸ” éœ€è¦ç™»å½• Google Cloud è´¦å·æ¥è®¿é—® GCS")
    print("   å°†æ‰“å¼€æµè§ˆå™¨è¿›è¡Œç™»å½•...\n")
    
    try:
        subprocess.check_call(["gcloud", "auth", "application-default", "login"])
        print("\nâœ… ç™»å½•æˆåŠŸï¼")
        return True
    except subprocess.CalledProcessError:
        print("\nâŒ ç™»å½•å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è¿è¡Œ: gcloud auth application-default login")
        return False
    except FileNotFoundError:
        print("\nâŒ æœªæ‰¾åˆ° gcloud å‘½ä»¤")
        return False


def ensure_gcs_ready(bucket_name: str) -> bool:
    """
    ç¡®ä¿ GCS ç¯å¢ƒå·²å‡†å¤‡å¥½
    
    Args:
        bucket_name: GCS bucket åç§°
        
    Returns:
        True å¦‚æœç¯å¢ƒå·²å‡†å¤‡å¥½
    """
    print(f"\nğŸ” æ£€æŸ¥ GCS ç¯å¢ƒ (bucket: {bucket_name})...")
    
    # 1. æ£€æŸ¥ Python åŒ…
    if not check_gcs_dependencies():
        print("âš ï¸  æœªå®‰è£… google-cloud-storageï¼Œæ­£åœ¨è‡ªåŠ¨å®‰è£…...")
        if not install_gcs_dependencies():
            return False
    
    # 2. æ£€æŸ¥ gcloud CLI
    # å…ˆæ£€æŸ¥ Homebrew å®‰è£…è·¯å¾„
    gcloud_brew_path = "/opt/homebrew/share/google-cloud-sdk/bin/gcloud"
    if os.path.exists(gcloud_brew_path):
        # æ·»åŠ åˆ°å½“å‰è¿›ç¨‹çš„ PATH
        gcloud_bin = "/opt/homebrew/share/google-cloud-sdk/bin"
        if gcloud_bin not in os.environ.get("PATH", ""):
            os.environ["PATH"] = f"{gcloud_bin}:{os.environ.get('PATH', '')}"
    
    if not shutil.which("gcloud"):
        print("âš ï¸  æœªå®‰è£… gcloud CLIï¼Œæ­£åœ¨è‡ªåŠ¨å®‰è£…...")
        if not install_gcloud_cli():
            return False
    
    # 3. æ£€æŸ¥æ˜¯å¦å·²ç™»å½•
    if not check_gcloud_auth():
        print("âš ï¸  æœªç™»å½• Google Cloudï¼Œæ­£åœ¨æ‰“å¼€ç™»å½•é¡µé¢...")
        if not setup_gcs_auth():
            return False
    
    print("âœ… GCS ç¯å¢ƒæ£€æŸ¥é€šè¿‡\n")
    return True


def setup_logging(level: str = "INFO", log_file: Optional[Path] = None):
    """é…ç½®æ—¥å¿—"""
    log_level = getattr(logging, level.upper(), logging.INFO)
    
    handlers = [logging.StreamHandler(sys.stdout)]
    
    if log_file:
        handlers.append(logging.FileHandler(log_file, encoding="utf-8"))
    
    # ç®€åŒ–æ—¥å¿—æ ¼å¼
    logging.basicConfig(
        level=log_level,
        format="%(asctime)s %(message)s",
        datefmt="%H:%M:%S",
        handlers=handlers,
    )
    
    # é™ä½ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—çº§åˆ«
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("httpcore").setLevel(logging.WARNING)
    logging.getLogger("MOSS_pro_utils").setLevel(logging.WARNING)
    logging.getLogger("ai_image_generator.moss_uploader").setLevel(logging.WARNING)


def create_engine(
    config_path: Path,
    template_path: Path,
    api_key: Optional[str] = None,
) -> GenerationEngine:
    """åˆ›å»ºç”Ÿæˆå¼•æ“"""
    # é…ç½®ç®¡ç†å™¨
    config_manager = ConfigManager(
        config_path=config_path,
        template_path=template_path,
    )
    
    # åŠ è½½é…ç½®
    global_config = config_manager.load_global_config()
    template_config = config_manager.load_template_config()
    
    # å¦‚æœæä¾›äº†APIå¯†é’¥ï¼Œè¦†ç›–é…ç½®
    if api_key:
        global_config.api_key = api_key
    
    # æ¨¡æ¿å¼•æ“
    prompts_dir = None
    # æ ¹æ®æ¨¡å¼è·å– prompt ç›®å½•
    if template_config.mode == "scene_generation" and template_config.scene_prompts:
        prompts_dir = config_manager.get_resolved_path("scene_prompts", template_config.scene_prompts.source_dir)
    elif template_config.mode == "subject_transfer" and template_config.transfer_prompts:
        prompts_dir = config_manager.get_resolved_path("transfer_prompts", template_config.transfer_prompts.source_dir)
    template_engine = TemplateEngine(template_dir=prompts_dir)
    
    # å›¾ç‰‡é€‰æ‹©å™¨
    image_selector = ImageSelector()
    
    # æ ¹æ® image_model åˆ¤æ–­æ˜¯å¦ä½¿ç”¨ OpenRouter
    image_model = template_config.image_model
    is_openrouter = image_model.startswith("openrouter/")
    
    # è­¦å‘Šï¼šMidjourney ä¸é€‚åˆä¸»ä½“è¿ç§»ä»»åŠ¡
    if image_model == "midjourney" and template_config.mode == "subject_transfer":
        logging.warning("âš ï¸ Midjourney ä¸é€‚åˆä¸»ä½“è¿ç§»ä»»åŠ¡ï¼")
        logging.warning("   Midjourney çš„ image-to-image æ˜¯é£æ ¼èåˆï¼Œæ— æ³•ç²¾ç¡®ä¿ç•™äº§å“ä¸»ä½“ã€‚")
        logging.warning("   å»ºè®®ä½¿ç”¨ nano-banana-pro æˆ– seedream/4.5-edit è¿›è¡Œä¸»ä½“è¿ç§»ã€‚")
    
    # æ ¹æ® storage_service å’Œ image_model é€‰æ‹©ä¸Šä¼ å™¨
    # KieAI æ¨¡å‹å¿…é¡»ä½¿ç”¨ MOSSï¼ˆKieAI API éœ€è¦ç›´æ¥è®¿é—® URLï¼‰
    # OpenRouter æ¨¡å‹å¯ä»¥é€‰æ‹© MOSS æˆ– GCS
    storage_service = global_config.storage_service
    
    if is_openrouter and storage_service == "gcs" and global_config.gcs_bucket_name:
        # OpenRouter + GCS
        if not ensure_gcs_ready(global_config.gcs_bucket_name):
            raise GeneratorError("GCS ç¯å¢ƒæœªå‡†å¤‡å¥½ï¼Œè¯·æŒ‰æç¤ºå®Œæˆé…ç½®åé‡è¯•")
        
        logging.info(f"ğŸ“¦ ä½¿ç”¨ Google Cloud Storage: {global_config.gcs_bucket_name}")
        uploader = GCSUploader(
            bucket_name=global_config.gcs_bucket_name,
            folder_path=global_config.gcs_folder_path,
            credentials_path=global_config.gcs_credentials_path or None,
            project_id=global_config.gcs_project_id or None,
            make_public=True,
        )
    else:
        # KieAI æˆ– OpenRouter + MOSS
        if not is_openrouter and storage_service == "gcs":
            logging.warning("âš ï¸ KieAI æ¨¡å‹ä¸æ”¯æŒ GCS å­˜å‚¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ° MOSS")
        uploader = MOSSUploader(
            base_url=global_config.moss_base_url,
            access_key_id=global_config.moss_access_key_id,
            access_key_secret=global_config.moss_access_key_secret,
            bucket_name=global_config.moss_bucket_name,
            expire_seconds=global_config.moss_expire_seconds,
        )
    
    # æ ¹æ® image_model é€‰æ‹©å›¾ç‰‡ç”Ÿæˆå®¢æˆ·ç«¯
    # æ‰€æœ‰ç”Ÿå›¾æ¨¡å‹ç»Ÿä¸€åœ¨ templates/generation_template.json çš„ image_model å­—æ®µé…ç½®
    api_client: Union[APIClient, OpenRouterImageClient, SeedreamClient, MidjourneyClient]
    
    if image_model == "openrouter/seedream-4.5":
        # OpenRouter Seedream 4.5
        logging.info(f"ğŸ“¡ ä½¿ç”¨ OpenRouter Seedream 4.5 å›¾ç‰‡ç”ŸæˆæœåŠ¡")
        if global_config.openrouter_image_proxy:
            logging.info(f"ğŸ“¡ ä½¿ç”¨ä»£ç†: {global_config.openrouter_image_proxy.split('@')[-1]}")
        api_client = OpenRouterImageClient(
            api_key=global_config.openrouter_image_api_key,
            base_url=global_config.openrouter_image_base_url,
            model="bytedance-seed/seedream-4.5",
            site_url=global_config.openrouter_image_site_url,
            site_name=global_config.openrouter_image_site_name,
            proxy=global_config.openrouter_image_proxy or None,
        )
    elif image_model == "openrouter/nano-banana-pro":
        # OpenRouter Nano Banana Pro (google/gemini-3-pro-image-preview)
        logging.info(f"ğŸ“¡ ä½¿ç”¨ OpenRouter Nano Banana Pro å›¾ç‰‡ç”ŸæˆæœåŠ¡")
        if global_config.openrouter_image_proxy:
            logging.info(f"ğŸ“¡ ä½¿ç”¨ä»£ç†: {global_config.openrouter_image_proxy.split('@')[-1]}")
        api_client = OpenRouterImageClient(
            api_key=global_config.openrouter_image_api_key,
            base_url=global_config.openrouter_image_base_url,
            model="google/gemini-3-pro-image-preview",
            site_url=global_config.openrouter_image_site_url,
            site_name=global_config.openrouter_image_site_name,
            proxy=global_config.openrouter_image_proxy or None,
        )
    elif image_model == "seedream/4.5-edit":
        # KieAI Seedream 4.5 Edit
        logging.info(f"ğŸ“¡ ä½¿ç”¨ KieAI Seedream 4.5 Edit å›¾ç‰‡ç”ŸæˆæœåŠ¡")
        api_client = SeedreamClient(
            api_key=global_config.api_key,
            base_url=global_config.api_base_url,
            model="seedream/4.5-edit",
            poll_interval=global_config.poll_interval,
            max_wait=global_config.max_wait,
        )
    elif image_model == "midjourney":
        # KieAI Midjourney image-to-image
        logging.info(f"ğŸ“¡ ä½¿ç”¨ KieAI Midjourney å›¾ç‰‡ç”ŸæˆæœåŠ¡")
        api_client = MidjourneyClient(
            api_key=global_config.api_key,
            base_url=global_config.api_base_url,
            version=global_config.midjourney_version,
            speed=global_config.midjourney_speed,
            poll_interval=global_config.poll_interval,
            max_wait=global_config.max_wait,
        )
    else:
        # é»˜è®¤ä½¿ç”¨ nano-banana-pro
        logging.info(f"ğŸ“¡ ä½¿ç”¨ KieAI å›¾ç‰‡ç”ŸæˆæœåŠ¡, model={image_model or global_config.model}")
        api_client = APIClient(
            api_key=global_config.api_key,
            base_url=global_config.api_base_url,
            model=image_model or global_config.model,
            poll_interval=global_config.poll_interval,
            max_wait=global_config.max_wait,
        )
    
    # è¾“å‡ºç®¡ç†å™¨
    output_base = config_manager.get_resolved_path("output_base", template_config.output.base_dir)
    output_manager = OutputManager(
        base_dir=output_base,
        run_name=template_config.name,
    )
    
    # çŠ¶æ€ç®¡ç†å™¨ï¼ˆåˆå§‹ç›®å½•ä¸ºè¾“å‡ºç›®å½•ï¼‰
    state_manager = StateManager(state_dir=output_base)
    
    # æ–‡æ¡ˆç”Ÿæˆå™¨ï¼ˆå¦‚æœé…ç½®äº† OpenRouterï¼‰
    text_generator = None
    if global_config.openrouter_api_key:
        text_generator = TextGenerator(
            api_key=global_config.openrouter_api_key,
            base_url=global_config.openrouter_base_url,
            model=global_config.openrouter_model,
            site_url=global_config.openrouter_site_url,
            site_name=global_config.openrouter_site_name,
            proxy=global_config.openrouter_proxy or None,
            reference_min_samples=global_config.reference_min_samples,
            reference_max_samples=global_config.reference_max_samples,
        )
        
        # åŠ è½½ Few-shot æ ·æœ¬
        text_gen_cfg = template_config.text_generation
        if text_gen_cfg:
            pass
    
    # åˆ›å»ºå¼•æ“
    return GenerationEngine(
        config_manager=config_manager,
        template_engine=template_engine,
        image_selector=image_selector,
        moss_uploader=uploader,  # å¯ä»¥æ˜¯ MOSSUploader æˆ– GCSUploader
        api_client=api_client,
        output_manager=output_manager,
        state_manager=state_manager,
        text_generator=text_generator,
    )


def validate_specified_images_coverage(source_dirs: List[str], specified_images: List[str]) -> List[str]:
    """
    éªŒè¯æ‰€æœ‰æŒ‡å®šçš„äº§å“å›¾éƒ½èƒ½åŒ¹é…åˆ°è‡³å°‘ä¸€ä¸ª source_dir
    
    Args:
        source_dirs: äº§å“å›¾æ–‡ä»¶å¤¹åˆ—è¡¨
        specified_images: ç”¨æˆ·æŒ‡å®šçš„äº§å“å›¾è·¯å¾„åˆ—è¡¨
        
    Returns:
        æ— æ³•åŒ¹é…çš„å›¾ç‰‡è·¯å¾„åˆ—è¡¨ï¼ˆç©ºåˆ—è¡¨è¡¨ç¤ºå…¨éƒ¨åŒ¹é…ï¼‰
    """
    if not specified_images:
        return []
    
    unmatched = []
    for img_path in specified_images:
        if not img_path or not img_path.strip():
            continue
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»æ„ä¸€ä¸ª source_dir
        matched = False
        for source_dir in source_dirs:
            source_dir_normalized = source_dir.rstrip("/")
            if img_path.startswith(source_dir_normalized + "/"):
                matched = True
                break
        
        if not matched:
            unmatched.append(img_path)
    
    return unmatched


def get_product_source_dirs(template_path: Path) -> List[str]:
    """
    ä»æ¨¡æ¿é…ç½®ä¸­è·å–äº§å“å›¾æºç›®å½•åˆ—è¡¨
    
    Args:
        template_path: æ¨¡æ¿é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        äº§å“å›¾æºç›®å½•åˆ—è¡¨ï¼ˆå³ä½¿é…ç½®çš„æ˜¯å•ä¸ªå­—ç¬¦ä¸²ä¹Ÿè¿”å›åˆ—è¡¨ï¼‰
    """
    with open(template_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    prod_cfg = data.get("product_images", {})
    source_dir = prod_cfg.get("source_dir", "")
    
    if isinstance(source_dir, list):
        # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
        return [d for d in source_dir if d and d.strip()]
    elif source_dir and source_dir.strip():
        return [source_dir]
    else:
        return []


def update_template_source_dir(template_path: Path, new_source_dir: str) -> Path:
    """
    åˆ›å»ºä¸´æ—¶æ¨¡æ¿é…ç½®ï¼Œæ›´æ–°äº§å“å›¾æºç›®å½•
    
    Args:
        template_path: åŸå§‹æ¨¡æ¿é…ç½®æ–‡ä»¶è·¯å¾„
        new_source_dir: æ–°çš„äº§å“å›¾æºç›®å½•
        
    Returns:
        ä¸´æ—¶æ¨¡æ¿é…ç½®æ–‡ä»¶è·¯å¾„
    """
    import tempfile
    
    with open(template_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    # æ›´æ–°äº§å“å›¾æºç›®å½•ä¸ºå•ä¸ªå­—ç¬¦ä¸²
    data["product_images"]["source_dir"] = new_source_dir
    
    # æ™ºèƒ½è¿‡æ»¤ specified_imagesï¼šåªä¿ç•™å±äºå½“å‰æ–‡ä»¶å¤¹çš„å›¾ç‰‡
    original_specified = data["product_images"].get("specified_images", [])
    if original_specified:
        # ç¡®ä¿æ˜¯åˆ—è¡¨
        if isinstance(original_specified, str):
            original_specified = [original_specified] if original_specified.strip() else []
        
        # è¿‡æ»¤ï¼šåªä¿ç•™è·¯å¾„ä»¥å½“å‰ source_dir å¼€å¤´çš„å›¾ç‰‡
        # æ ‡å‡†åŒ–è·¯å¾„è¿›è¡Œæ¯”è¾ƒ
        source_dir_normalized = new_source_dir.rstrip("/")
        filtered_specified = [
            img for img in original_specified
            if img and img.strip() and img.startswith(source_dir_normalized + "/")
        ]
        data["product_images"]["specified_images"] = filtered_specified
    
    # æ ¹æ®æ–°ç›®å½•æ›´æ–°æ¨¡æ¿åç§°ï¼ˆä½¿ç”¨æ–‡ä»¶å¤¹åä½œä¸ºåç¼€ï¼‰
    folder_name = Path(new_source_dir).name
    original_name = data.get("name", "ç”Ÿæˆä»»åŠ¡")
    # é¿å…é‡å¤æ·»åŠ åç¼€ï¼ˆå¦‚æœåŸåç§°å·²ç»åŒ…å«æ–‡ä»¶å¤¹åï¼‰
    if not original_name.endswith(f"_{folder_name}"):
        data["name"] = f"{original_name}_{folder_name}"
    
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    fd, temp_path = tempfile.mkstemp(suffix=".json", prefix="template_")
    with os.fdopen(fd, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    return Path(temp_path)


def main():
    """ä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        description="AIå›¾ç‰‡ç”Ÿæˆå™¨ - æ‰¹é‡ç”Ÿæˆäº§å“åœºæ™¯å›¾",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æ–°è¿è¡Œï¼ˆä½¿ç”¨é»˜è®¤æ¨¡æ¿ï¼‰
  python -m ai_image_generator
  
  # æŒ‡å®šæ¨¡æ¿è¿è¡Œ
  python -m ai_image_generator -t templates/scene_generation_template.json
  
  # éªŒè¯é…ç½®
  python -m ai_image_generator --dry-run
  
  # æ–­ç‚¹ç»­ä¼ ï¼ˆç›´æ¥ä¼ å…¥ä¹‹å‰çš„è¿è¡Œç›®å½•ï¼‰
  python -m ai_image_generator outputs/æµ·æ´‹è‡³å°Š_20260126_143000
  
  # å¤šäº§å“å›¾æ–‡ä»¶å¤¹æ‰¹é‡ç”Ÿæˆï¼ˆåœ¨æ¨¡æ¿ä¸­é…ç½® source_dir ä¸ºæ•°ç»„ï¼‰
  # "source_dir": ["äº§å“å›¾/æµ·æ´‹è‡³å°Š", "äº§å“å›¾/åŒ–å¦†å“2", "äº§å“å›¾/åŒ–å¦†å“3"]
        """,
    )
    
    # ä½ç½®å‚æ•°ï¼šæ–­ç‚¹ç»­ä¼ ç›®å½•ï¼ˆå¯é€‰ï¼‰
    parser.add_argument(
        "resume_dir",
        nargs="?",
        default=None,
        help="æ–­ç‚¹ç»­ä¼ ï¼šæŒ‡å®šä¹‹å‰çš„è¿è¡Œç›®å½•è·¯å¾„",
    )
    
    parser.add_argument(
        "-t", "--template",
        default="templates/generation_template.json",
        help="æ¨¡æ¿é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: templates/generation_template.json)",
    )
    
    parser.add_argument(
        "-c", "--config",
        default="config.json",
        help="å…¨å±€é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.json)",
    )
    
    parser.add_argument(
        "--api-key",
        help="APIå¯†é’¥ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰",
    )
    
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="è¯•è¿è¡Œæ¨¡å¼ï¼ŒåªéªŒè¯é…ç½®ä¸æ‰§è¡Œç”Ÿæˆ",
    )
    
    parser.add_argument(
        "-y", "--yes",
        action="store_true",
        help="è‡ªåŠ¨ç¡®è®¤ï¼Œè·³è¿‡æ‰€æœ‰ç¡®è®¤æç¤º",
    )
    
    parser.add_argument(
        "--log-level",
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        help="æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)",
    )
    
    args = parser.parse_args()
    
    # é…ç½®æ—¥å¿—
    setup_logging(level=args.log_level)
    logger = logging.getLogger(__name__)
    
    try:
        config_path = Path(args.config)
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºæ–­ç‚¹ç»­ä¼ æ¨¡å¼
        if args.resume_dir:
            # æ–­ç‚¹ç»­ä¼ æ¨¡å¼
            resume_path = Path(args.resume_dir)
            
            # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
            if not resume_path.exists():
                logger.error(f"ç›®å½•ä¸å­˜åœ¨: {resume_path}")
                return 1
            
            if not resume_path.is_dir():
                logger.error(f"è·¯å¾„ä¸æ˜¯ç›®å½•: {resume_path}")
                return 1
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ results.json
            results_file = resume_path / "results.json"
            if not results_file.exists():
                logger.error(f"è¯¥ç›®å½•ä¸æ˜¯æœ‰æ•ˆçš„è¿è¡Œç›®å½•ï¼ˆç¼ºå°‘ results.jsonï¼‰: {resume_path}")
                return 1
            
            # åŠ è½½çŠ¶æ€è·å–æ¨¡æ¿é…ç½®è·¯å¾„
            state_manager = StateManager(state_dir=resume_path)
            state = state_manager.load_state()
            
            if not state:
                logger.error("çŠ¶æ€æ–‡ä»¶æŸåï¼Œæ— æ³•æ¢å¤")
                return 1
            
            # ä»çŠ¶æ€ä¸­è·å–æ¨¡æ¿é…ç½®è·¯å¾„
            template_path = Path(state.template_config_path)
            if not template_path.exists():
                logger.error(f"æ¨¡æ¿é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {template_path}")
                return 1
            
            logger.info(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ æ¨¡å¼: {resume_path}")
            logger.info(f"   ä½¿ç”¨æ¨¡æ¿: {template_path}")
            
            # åˆ›å»ºå¼•æ“
            engine = create_engine(
                config_path=config_path,
                template_path=template_path,
                api_key=args.api_key,
            )
            
            # è®¾ç½®è¾“å‡ºç›®å½•ä¸ºæ¢å¤ç›®å½•
            engine.output_manager.set_run_dir(resume_path)
            engine.state_manager.state_dir = resume_path
            engine.state_manager._state = state
            
            # æ‰§è¡Œï¼ˆä¼šè‡ªåŠ¨è·³è¿‡å·²å®Œæˆçš„ç»„ï¼‰
            result = engine.run(dry_run=args.dry_run, auto_confirm=args.yes)
            
            # è¾“å‡ºç»“æœ
            print(json.dumps(result.to_dict(), ensure_ascii=False, indent=2))
            return 0
        
        # æ–°è¿è¡Œæ¨¡å¼
        template_path = Path(args.template)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªäº§å“å›¾æ–‡ä»¶å¤¹
        source_dirs = get_product_source_dirs(template_path)
        
        if len(source_dirs) <= 1:
            # å•ä¸ªæ–‡ä»¶å¤¹ï¼Œæ­£å¸¸æ‰§è¡Œ
            engine = create_engine(
                config_path=config_path,
                template_path=template_path,
                api_key=args.api_key,
            )
            result = engine.run(dry_run=args.dry_run, auto_confirm=args.yes)
            print(json.dumps(result.to_dict(), ensure_ascii=False, indent=2))
            return 0
        
        # å¤šä¸ªäº§å“å›¾æ–‡ä»¶å¤¹ï¼Œå¾ªç¯æ‰§è¡Œ
        logger.info(f"ğŸ“‚ æ£€æµ‹åˆ° {len(source_dirs)} ä¸ªäº§å“å›¾æ–‡ä»¶å¤¹ï¼Œå°†ä¾æ¬¡æ‰§è¡Œ:")
        for i, d in enumerate(source_dirs, 1):
            logger.info(f"   {i}. {d}")
        print()
        
        # éªŒè¯ specified_images éƒ½èƒ½åŒ¹é…åˆ° source_dir
        with open(template_path, "r", encoding="utf-8") as f:
            template_data = json.load(f)
        specified_images = template_data.get("product_images", {}).get("specified_images", [])
        if isinstance(specified_images, str):
            specified_images = [specified_images] if specified_images.strip() else []
        
        unmatched_images = validate_specified_images_coverage(source_dirs, specified_images)
        if unmatched_images:
            logger.error("âŒ ä»¥ä¸‹æŒ‡å®šçš„äº§å“å›¾è·¯å¾„ä¸å±äºä»»ä½• source_dir æ–‡ä»¶å¤¹:")
            for img in unmatched_images:
                logger.error(f"   - {img}")
            logger.error(f"   å¯ç”¨çš„ source_dir: {source_dirs}")
            raise GeneratorError(f"æŒ‡å®šçš„äº§å“å›¾è·¯å¾„æ— æ•ˆ: {', '.join(unmatched_images)}")
        
        all_results = []
        temp_files = []  # è®°å½•ä¸´æ—¶æ–‡ä»¶ï¼Œæœ€åæ¸…ç†
        results_lock = threading.Lock()  # ç»“æœåˆ—è¡¨é”
        
        def execute_source_dir(idx: int, source_dir: str) -> dict:
            """æ‰§è¡Œå•ä¸ªäº§å“å›¾æ–‡ä»¶å¤¹çš„ç”Ÿæˆä»»åŠ¡"""
            folder_name = Path(source_dir).name
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ“¦ [{idx}/{len(source_dirs)}] å¼€å§‹å¤„ç†: {folder_name}")
            logger.info(f"{'='*60}\n")
            
            # åˆ›å»ºä¸´æ—¶æ¨¡æ¿é…ç½®
            temp_template = update_template_source_dir(template_path, source_dir)
            with results_lock:
                temp_files.append(temp_template)
            
            # åˆ›å»ºå¼•æ“
            engine = create_engine(
                config_path=config_path,
                template_path=temp_template,
                api_key=args.api_key,
            )
            
            # æ‰§è¡Œ
            result = engine.run(dry_run=args.dry_run, auto_confirm=args.yes)
            
            logger.info(f"\nâœ… [{idx}/{len(source_dirs)}] {folder_name} å®Œæˆ")
            
            return {
                "source_dir": source_dir,
                "folder_name": folder_name,
                "result": result.to_dict(),
            }
        
        try:
            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æ–‡ä»¶å¤¹
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor(max_workers=len(source_dirs)) as executor:
                futures = {
                    executor.submit(execute_source_dir, idx, source_dir): source_dir
                    for idx, source_dir in enumerate(source_dirs, 1)
                }
                
                for future in concurrent.futures.as_completed(futures):
                    source_dir = futures[future]
                    try:
                        result = future.result()
                        with results_lock:
                            all_results.append(result)
                    except Exception as e:
                        folder_name = Path(source_dir).name
                        logger.error(f"âŒ {folder_name} æ‰§è¡Œå¤±è´¥: {e}")
                        with results_lock:
                            all_results.append({
                                "source_dir": source_dir,
                                "folder_name": folder_name,
                                "result": {"error": str(e)},
                            })
            
            # è¾“å‡ºæ±‡æ€»ç»“æœ
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ‰ å…¨éƒ¨å®Œæˆï¼å…±å¤„ç† {len(source_dirs)} ä¸ªäº§å“å›¾æ–‡ä»¶å¤¹")
            logger.info(f"{'='*60}\n")
            
            # æ±‡æ€»ç»Ÿè®¡
            total_images = sum(r["result"]["total_images"] for r in all_results)
            successful_images = sum(r["result"]["successful_images"] for r in all_results)
            failed_images = sum(r["result"]["failed_images"] for r in all_results)
            total_duration = sum(r["result"]["duration_seconds"] for r in all_results)
            
            summary = {
                "total_source_dirs": len(source_dirs),
                "total_images": total_images,
                "successful_images": successful_images,
                "failed_images": failed_images,
                "total_duration_seconds": total_duration,
                "results": all_results,
            }
            
            print(json.dumps(summary, ensure_ascii=False, indent=2))
            return 0
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for temp_file in temp_files:
                try:
                    if temp_file.exists():
                        temp_file.unlink()
                except Exception:
                    pass
    
    except GeneratorError as e:
        logger.error(f"ç”Ÿæˆé”™è¯¯: {e}")
        print(json.dumps({"error": str(e)}, ensure_ascii=False))
        return 1
    
    except Exception as e:
        logger.exception(f"æœªçŸ¥é”™è¯¯: {e}")
        print(json.dumps({"error": str(e)}, ensure_ascii=False))
        return 1


if __name__ == "__main__":
    sys.exit(main())
